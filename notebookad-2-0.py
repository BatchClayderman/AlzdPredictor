# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
input_folder_path = './kaggle/input/alzheimer/data/'
result_folder_path = './results/'

cnt = 0
for root, _, filenames in os.walk(input_folder_path):
    for filename in filenames:
        cnt += 1
print('Gathered {0} data file(s) under the directory \"{1}\". '.format(cnt, input_folder_path))
os.makedirs(result_folder_path, exist_ok = True)

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# -*- coding: utf-8 -*-
"""
é˜¿å°”èŒ¨æµ·é»˜ç—‡å¤šæ¨¡æ€è¯†åˆ«ç³»ç»Ÿ - å®Œæ•´å¯è§†åŒ–ç‰ˆ
é›†æˆè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ï¼Œä¸­æ–‡æ³¨é‡Šï¼Œè‹±æ–‡æ ‡ç­¾æ˜¾ç¤º
"""

import numpy as np
import pandas as pd
import time
from tqdm import tqdm
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import (roc_auc_score, recall_score, f1_score, 
                           accuracy_score, classification_report, 
                           confusion_matrix, precision_score)
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
import torch.nn.functional as F
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®
plt.rcParams['font.size'] = 12
plt.rcParams['font.family'] = 'DejaVu Sans'
sns.set_style("whitegrid")

SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# ========================== çœŸå®žæ•°æ®å¤„ç†å™¨ ==========================
class RealDataProcessor:
    """çœŸå®žæ•°æ®å¤„ç†å™¨ - åŸºäºŽå®žé™…æ•°æ®ç»“æž„"""

    def __init__(self, base_path = input_folder_path):
        self.base_path = base_path
        self.egemaps_pre_path = os.path.join(base_path, 'egemaps_final.csv')
        self.train_list_path = os.path.join(base_path, '2_final_list_train.csv')
        self.test_list_path = os.path.join(base_path, '2_final_list_test.csv')
        self.tsv_dir = os.path.join(base_path, 'tsv2/')
        self.egemaps_dir = '/data/egemaps2/'  # æ ¹æ®å®žé™…æƒ…å†µæ›´æ–°è·¯å¾„

    def process_all_data(self):
        """å¤„ç†æ‰€æœ‰æ•°æ®"""
        print("=== Processing Real Alzheimer's Disease Data ===")

        # 1. åŠ è½½åŸºç¡€æ•°æ®
        print("1. Loading basic data...")
        preliminary_list_test = pd.read_csv(self.test_list_path)  # (27,2)
        preliminary_list_train = pd.read_csv(self.train_list_path)  # (179,2)
        egemaps_pre = pd.read_csv(self.egemaps_pre_path)  # (206,89)

        print(f"Training set: {preliminary_list_train.shape}")
        print(f"Test set: {preliminary_list_test.shape}")
        print(f"Precomputed features: {egemaps_pre.shape}")
        print('Training set label distribution:\n', preliminary_list_train['label'].value_counts())

        # 2. ä»ŽTSVæ–‡ä»¶æå–æ–‡æœ¬ç‰¹å¾
        print("\n2. Extracting text features from TSV files...")
        text_features = self._extract_text_features()

        # 3. ä»ŽeGeMAPSæ–‡ä»¶æå–éŸ³é¢‘ç‰¹å¾
        print("\n3. Extracting audio features from eGeMAPS files...")
        audio_features = self._extract_audio_features()

        # 4. åˆå¹¶æ‰€æœ‰ç‰¹å¾
        print("\n4. Merging all features...")
        merged_data = self._merge_all_features(
            preliminary_list_train, preliminary_list_test, 
            egemaps_pre, text_features, audio_features
        )

        return merged_data

    def _extract_text_features(self):
        """ä»ŽTSVæ–‡ä»¶æå–æ–‡æœ¬ç‰¹å¾"""
        tsv_path_lists = os.listdir(self.tsv_dir)
        tsv_feats = []

        print(f"Processing {len(tsv_path_lists)} TSV files...")

        for path in tqdm(tsv_path_lists):
            try:
                # è¯»å–tsvæ–‡ä»¶
                z = pd.read_csv(os.path.join(self.tsv_dir, path), sep='\t')
                # è®¡ç®—æ¯å¥è¯çš„æ—¶é•¿
                z['end_time-start_time'] = z['end_time'] - z['start_time']

                # æå–æ—¶é•¿ç»Ÿè®¡ç‰¹å¾
                tsv_feats.append([
                    path[:-4],  # uuid
                    z['end_time-start_time'].mean(),    # å¹³å‡æ—¶é•¿
                    z['end_time-start_time'].min(),     # æœ€å°æ—¶é•¿
                    z['end_time-start_time'].max(),     # æœ€å¤§æ—¶é•¿
                    z['end_time-start_time'].std(),     # æ—¶é•¿æ ‡å‡†å·®
                    z['end_time-start_time'].median(),  # æ—¶é•¿ä¸­ä½æ•°
                    z['end_time-start_time'].skew(),    # æ—¶é•¿ååº¦
                    z.shape[0]                         # å¥å­æ•°é‡
                ])
            except Exception as e:
                print(f"Error processing file {path}: {e}")
                continue

        # è½¬æ¢ä¸ºDataFrame
        tsv_feats_df = pd.DataFrame(tsv_feats)
        tsv_feats_df.columns = ['uuid'] + [f'text_feat_{i}' for i in range(tsv_feats_df.shape[1] - 1)]

        print(f"Text features extracted: {tsv_feats_df.shape}")
        return tsv_feats_df

    def _extract_audio_features(self):
        """ä»ŽeGeMAPSæ–‡ä»¶æå–éŸ³é¢‘ç‰¹å¾"""
        try:
            egemaps_path_lists = os.listdir(self.egemaps_dir)
        except:
            print(f"eGeMAPS directory not found: {self.egemaps_dir}")
            return None

        egemaps_feats = []

        print(f"Processing {len(egemaps_path_lists)} eGeMAPS files...")

        for path in tqdm(egemaps_path_lists):
            try:
                # è¯»å–æ–‡ä»¶ï¼ˆåˆ†éš”ç¬¦æ˜¯;ï¼‰
                z = pd.read_csv(os.path.join(self.egemaps_dir, path), sep=';')
                # ç§»é™¤nameåˆ—
                if 'name' in z.columns:
                    z = z.drop(['name'], axis=1)

                # æå–æ¯åˆ—çš„ç»Ÿè®¡ç‰¹å¾
                feature_vector = [path[:-4]]  # uuid

                # å‡å€¼ã€æ ‡å‡†å·®ã€æœ€å°å€¼ã€ä¸­ä½æ•°
                feature_vector.extend(list(z.mean(axis=0)))    # å‡å€¼
                feature_vector.extend(list(z.std(axis=0)))     # æ ‡å‡†å·®
                feature_vector.extend(list(z.min(axis=0)))     # æœ€å°å€¼
                feature_vector.extend(list(z.median(axis=0)))  # ä¸­ä½æ•°

                egemaps_feats.append(feature_vector)

            except Exception as e:
                print(f"Error processing audio file {path}: {e}")
                continue

        if egemaps_feats:
            # è½¬æ¢ä¸ºDataFrame
            egemaps_feats_df = pd.DataFrame(egemaps_feats)
            n_features = (egemaps_feats_df.shape[1] - 1) // 4
            columns = ['uuid']

            # åˆ›å»ºæè¿°æ€§åˆ—å
            for stat in ['mean', 'std', 'min', 'median']:
                for i in range(n_features):
                    columns.append(f'audio_{stat}_{i:03d}')

            egemaps_feats_df.columns = columns[:egemaps_feats_df.shape[1]]
            print(f"Audio features extracted: {egemaps_feats_df.shape}")
            return egemaps_feats_df
        else:
            return None

    def _merge_all_features(self, train_list, test_list, egemaps_pre, text_features, audio_features):
        """åˆå¹¶æ‰€æœ‰ç‰¹å¾"""
        print("Merging features...")

        # åˆå¹¶è®­ç»ƒå’Œæµ‹è¯•é›†
        all_data = pd.concat([train_list, test_list], ignore_index=True)
        print(f"Combined data: {all_data.shape}")

        # ç¡®ä¿uuidåˆ—ç±»åž‹ä¸€è‡´
        all_data['uuid'] = all_data['uuid'].astype(str)
        egemaps_pre['uuid'] = egemaps_pre['uuid'].astype(str)
        text_features['uuid'] = text_features['uuid'].astype(str)

        # åˆå¹¶é¢„è®¡ç®—çš„eGeMAPSç‰¹å¾
        merged_data = pd.merge(all_data, egemaps_pre, on='uuid', how='left')
        print(f"After eGeMAPS merge: {merged_data.shape}")

        # åˆå¹¶æ–‡æœ¬ç‰¹å¾
        merged_data = pd.merge(merged_data, text_features, on='uuid', how='left')
        print(f"After text features merge: {merged_data.shape}")

        # åˆå¹¶éŸ³é¢‘ç‰¹å¾ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if audio_features is not None:
            audio_features['uuid'] = audio_features['uuid'].astype(str)
            merged_data = pd.merge(merged_data, audio_features, on='uuid', how='left')
            print(f"After audio features merge: {merged_data.shape}")

        # æ•°æ®æ¸…æ´—
        merged_data = self._clean_data(merged_data)

        print(f"Final merged data shape: {merged_data.shape}")
        print("Label distribution in final data:")
        print(merged_data['label'].value_counts())

        return merged_data

    def _clean_data(self, data):
        """æ¸…æ´—å’Œé¢„å¤„ç†æ•°æ®"""
        # ç§»é™¤ç¼ºå¤±æ ‡ç­¾çš„è¡Œ
        data = data[data['label'].notna()]
        data = data[data['label'] != '']
        data = data[data['label'] != 'nan']

        # æ ‡å‡†åŒ–æ ‡ç­¾
        data['label'] = data['label'].astype(str).str.upper().str.strip()

        # å¡«å……ç‰¹å¾åˆ—çš„ç¼ºå¤±å€¼
        feature_columns = [col for col in data.columns if col not in ['uuid', 'label', 'sex', 'age', 'education']]
        data[feature_columns] = data[feature_columns].fillna(data[feature_columns].mean())

        return data

# ========================== å¢žå¼ºç‰¹å¾å·¥ç¨‹ ==========================
class EnhancedFeatureEngineering:
    """å¢žå¼ºç‰¹å¾å·¥ç¨‹"""

    def __init__(self):
        self.scaler_audio = StandardScaler()
        self.scaler_text = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.audio_columns = None
        self.text_columns = None
        self.selected_audio_columns = None
        self.selected_text_columns = None

    def prepare_features(self, data):
        """å‡†å¤‡ç‰¹å¾ç”¨äºŽæ¨¡åž‹è®­ç»ƒ"""
        print("\n=== Feature Engineering ===")

        # ç¼–ç æ ‡ç­¾
        labels = self.label_encoder.fit_transform(data['label'])
        label_mapping = dict(zip(self.label_encoder.classes_, range(len(self.label_encoder.classes_))))
        print(f"Label encoding: {label_mapping}")

        # è¯†åˆ«ç‰¹å¾åˆ—
        feature_columns = [col for col in data.columns if col not in ['uuid', 'label', 'sex', 'age', 'education']]

        # åˆ†ç¦»éŸ³é¢‘å’Œæ–‡æœ¬ç‰¹å¾
        self.audio_columns = [col for col in feature_columns if any(keyword in col.lower() for keyword in 
                            ['f0', 'rms', 'mfcc', 'spectral', 'energy', 'loudness', 'jitter', 'shimmer', 'hnr', 'audio'])]
        self.text_columns = [col for col in feature_columns if any(keyword in col.lower() for keyword in 
                           ['text_feat', 'duration', 'sentence'])]

        # å¦‚æžœè‡ªåŠ¨æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨æ‰‹åŠ¨åˆ†é…
        if not self.audio_columns:
            # å‡è®¾å‰88åˆ—æ˜¯éŸ³é¢‘ç‰¹å¾
            self.audio_columns = feature_columns[:88]
        if not self.text_columns:
            # å‰©ä½™åˆ—æ˜¯æ–‡æœ¬ç‰¹å¾
            self.text_columns = [col for col in feature_columns if col not in self.audio_columns]

        print(f"Audio features identified: {len(self.audio_columns)}")
        print(f"Text features identified: {len(self.text_columns)}")

        # ç‰¹å¾é€‰æ‹©
        selected_audio, selected_text = self._select_features(
            data[self.audio_columns], data[self.text_columns], labels
        )

        # æ ‡å‡†åŒ–
        audio_features = self.scaler_audio.fit_transform(selected_audio)
        text_features = self.scaler_text.fit_transform(selected_text)

        print(f"Final feature dimensions - Audio: {audio_features.shape}, Text: {text_features.shape}")

        return audio_features, text_features, labels

    def _select_features(self, audio_data, text_data, labels):
        """é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾"""
        print("Performing feature selection...")

        # éŸ³é¢‘ç‰¹å¾é€‰æ‹©
        if audio_data.shape[1] > 50:
            selector_audio = SelectKBest(f_classif, k=min(50, audio_data.shape[1]))
            audio_selected = selector_audio.fit_transform(audio_data, labels)
            self.selected_audio_columns = [self.audio_columns[i] for i in selector_audio.get_support(indices=True)]
            print(f"Selected {len(self.selected_audio_columns)} audio features")
        else:
            audio_selected = audio_data.values
            self.selected_audio_columns = self.audio_columns

        # æ–‡æœ¬ç‰¹å¾é€‰æ‹©
        if text_data.shape[1] > 15:
            selector_text = SelectKBest(f_classif, k=min(15, text_data.shape[1]))
            text_selected = selector_text.fit_transform(text_data, labels)
            self.selected_text_columns = [self.text_columns[i] for i in selector_text.get_support(indices=True)]
            print(f"Selected {len(self.selected_text_columns)} text features")
        else:
            text_selected = text_data.values
            self.selected_text_columns = self.text_columns

        return audio_selected, text_selected

# ========================== ç¨³å®šæ¨¡åž‹æž¶æž„ ==========================
class StableAlzheimerNet(nn.Module):
    """ç¨³å®šçš„é˜¿å°”èŒ¨æµ·é»˜ç—‡è¯†åˆ«ç½‘ç»œ"""

    def __init__(self, audio_dim, text_dim, num_classes=3):
        super(StableAlzheimerNet, self).__init__()

        # éŸ³é¢‘ç¼–ç å™¨
        self.audio_encoder = nn.Sequential(
            nn.Linear(audio_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
        )

        # æ–‡æœ¬ç¼–ç å™¨
        self.text_encoder = nn.Sequential(
            nn.Linear(text_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
        )

        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(64 + 32, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, num_classes)
        )

    def forward(self, audio_features, text_features):
        audio_encoded = self.audio_encoder(audio_features)
        text_encoded = self.text_encoder(text_features)

        # æ‹¼æŽ¥ç‰¹å¾
        combined = torch.cat([audio_encoded, text_encoded], dim=1)
        output = self.classifier(combined)

        return output

# ========================== å¢žå¼ºè®­ç»ƒç³»ç»Ÿï¼ˆå¸¦è¯¦ç»†å¯è§†åŒ–ï¼‰ ==========================
class EnhancedTrainingSystem:
    """å¢žå¼ºè®­ç»ƒç³»ç»Ÿ - å¸¦è¯¦ç»†è®­ç»ƒè¿‡ç¨‹è·Ÿè¸ªå’Œå¯è§†åŒ–"""

    def __init__(self):
        self.models = {}
        self.predictions = {}
        self.training_histories = {}
        self.model_performances = {}
        self.epoch_details = {}  # å­˜å‚¨æ¯ä¸ªepochçš„è¯¦ç»†ä¿¡æ¯

    def train_enhanced_system(self, audio_features, text_features, labels, feature_engineer):
        """è®­ç»ƒå¢žå¼ºç³»ç»Ÿ"""
        print("\n=== Training Enhanced System ===")

        # 1. æ·±åº¦å­¦ä¹ æ¨¡åž‹ï¼ˆä¸»è¦ç„¦ç‚¹ï¼‰
        print("1. Training Deep Learning Model...")
        dl_predictions, dl_model, dl_history, dl_epoch_details = self._train_deep_learning_with_details(
            audio_features, text_features, labels, feature_engineer
        )
        self.models['Deep Learning'] = dl_model
        self.predictions['Deep Learning'] = dl_predictions
        self.training_histories['Deep Learning'] = dl_history
        self.epoch_details['Deep Learning'] = dl_epoch_details

        # 2. LightGBMæ¨¡åž‹
        print("2. Training LightGBM Model...")
        lgb_predictions, lgb_model, lgb_scores = self._train_lightgbm(
            audio_features, text_features, labels
        )
        self.models['LightGBM'] = lgb_model
        self.predictions['LightGBM'] = lgb_predictions
        self.model_performances['LightGBM'] = lgb_scores

        # 3. éšæœºæ£®æž—æ¨¡åž‹
        print("3. Training Random Forest Model...")
        rf_predictions, rf_model, rf_scores = self._train_random_forest(
            audio_features, text_features, labels
        )
        self.models['Random Forest'] = rf_model
        self.predictions['Random Forest'] = rf_predictions
        self.model_performances['Random Forest'] = rf_scores

        # 4. æ¢¯åº¦æå‡æ¨¡åž‹
        print("4. Training Gradient Boosting Model...")
        gb_predictions, gb_model, gb_scores = self._train_gradient_boosting(
            audio_features, text_features, labels
        )
        self.models['Gradient Boosting'] = gb_model
        self.predictions['Gradient Boosting'] = gb_predictions
        self.model_performances['Gradient Boosting'] = gb_scores

        # 5. æ¨¡åž‹é›†æˆ
        print("5. Model Ensemble...")
        ensemble_predictions = self._ensemble_predictions(labels)

        return ensemble_predictions

    def _train_deep_learning_with_details(self, audio_features, text_features, labels, feature_engineer):
        """è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡åž‹ - å¸¦è¯¦ç»†è®­ç»ƒè¿‡ç¨‹è·Ÿè¸ª"""
        # æ•°æ®åˆ†å‰²
        indices = np.arange(len(labels))
        train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=SEED, stratify=labels)

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TensorDataset(
            torch.FloatTensor(audio_features[train_idx]),
            torch.FloatTensor(text_features[train_idx]),
            torch.LongTensor(labels[train_idx])
        )
        val_dataset = TensorDataset(
            torch.FloatTensor(audio_features[val_idx]),
            torch.FloatTensor(text_features[val_idx]),
            torch.LongTensor(labels[val_idx])
        )

        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

        # åˆ›å»ºæ¨¡åž‹
        model = StableAlzheimerNet(
            audio_features.shape[1],
            text_features.shape[1],
            num_classes=len(feature_engineer.label_encoder.classes_)
        ).to(device)

        # è®­ç»ƒè®¾ç½®
        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
        criterion = nn.CrossEntropyLoss()

        # è®­ç»ƒåŽ†å²è®°å½•
        train_losses = []
        val_losses = []
        train_accuracies = []
        val_accuracies = []
        learning_rates = []

        # è¯¦ç»†epochä¿¡æ¯
        epoch_details = {
            'epochs': [],
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'learning_rate': [],
            'grad_norm': []
        }

        best_val_acc = 0
        patience = 25
        no_improve = 0

        print("Deep Learning Training Progress:")
        print("Epoch | Train Loss | Val Loss | Train Acc | Val Acc | LR")
        print("-" * 60)

        for epoch in range(300):  # å¢žåŠ è®­ç»ƒè½®æ¬¡
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            epoch_train_loss = 0
            train_correct = 0
            train_total = 0
            total_grad_norm = 0

            for audio_batch, text_batch, labels_batch in train_loader:
                audio_batch, text_batch, labels_batch = (
                    audio_batch.to(device), text_batch.to(device), labels_batch.to(device)
                )

                optimizer.zero_grad()
                outputs = model(audio_batch, text_batch)
                loss = criterion(outputs, labels_batch)
                loss.backward()

                # æ¢¯åº¦è£å‰ªå’Œè®°å½•
                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                total_grad_norm += grad_norm.item()

                optimizer.step()

                epoch_train_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                train_total += labels_batch.size(0)
                train_correct += (predicted == labels_batch).sum().item()

            avg_grad_norm = total_grad_norm / len(train_loader)
            train_acc = train_correct / train_total
            train_losses.append(epoch_train_loss / len(train_loader))
            train_accuracies.append(train_acc)

            # éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss = 0
            val_correct = 0
            val_total = 0

            with torch.no_grad():
                for audio_batch, text_batch, labels_batch in val_loader:
                    audio_batch, text_batch, labels_batch = (
                        audio_batch.to(device), text_batch.to(device), labels_batch.to(device)
                    )
                    outputs = model(audio_batch, text_batch)
                    loss = criterion(outputs, labels_batch)
                    val_loss += loss.item()

                    _, predicted = torch.max(outputs.data, 1)
                    val_total += labels_batch.size(0)
                    val_correct += (predicted == labels_batch).sum().item()

            val_acc = val_correct / val_total
            val_losses.append(val_loss / len(val_loader))
            val_accuracies.append(val_acc)

            # å­¦ä¹ çŽ‡è®°å½•
            current_lr = optimizer.param_groups[0]['lr']
            learning_rates.append(current_lr)

            # è®°å½•è¯¦ç»†epochä¿¡æ¯
            epoch_details['epochs'].append(epoch)
            epoch_details['train_loss'].append(epoch_train_loss / len(train_loader))
            epoch_details['val_loss'].append(val_loss / len(val_loader))
            epoch_details['train_acc'].append(train_acc)
            epoch_details['val_acc'].append(val_acc)
            epoch_details['learning_rate'].append(current_lr)
            epoch_details['grad_norm'].append(avg_grad_norm)

            # æ¯20ä¸ªepochæ‰“å°è¿›åº¦
            if epoch % 20 == 0:
                print(f"{epoch:5d} | {epoch_train_loss/len(train_loader):10.4f} | {val_loss/len(val_loader):8.4f} | "
                      f"{train_acc:9.4f} | {val_acc:7.4f} | {current_lr:.6f}")

            # æ—©åœæ£€æŸ¥
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                no_improve = 0
                best_model_state = model.state_dict().copy()
                best_epoch = epoch
            else:
                no_improve += 1
                if no_improve >= patience:
                    print(f"Early stopping at epoch {epoch}, best validation accuracy: {best_val_acc:.4f} at epoch {best_epoch}")
                    break

        model.load_state_dict(best_model_state)

        # æœ€ç»ˆé¢„æµ‹
        model.eval()
        with torch.no_grad():
            audio_tensor = torch.FloatTensor(audio_features).to(device)
            text_tensor = torch.FloatTensor(text_features).to(device)
            outputs = model(audio_tensor, text_tensor)
            _, predictions = torch.max(outputs, 1)

        accuracy = accuracy_score(labels, predictions.cpu().numpy())
        print(f"  Deep Learning Final Accuracy: {accuracy:.4f}")

        history = {
            'train_loss': train_losses,
            'val_loss': val_losses,
            'train_acc': train_accuracies,
            'val_acc': val_accuracies,
            'learning_rates': learning_rates
        }

        return predictions.cpu().numpy(), model, history, epoch_details

    def _train_lightgbm(self, audio_features, text_features, labels):
        """è®­ç»ƒLightGBMæ¨¡åž‹"""
        combined_features = np.concatenate([audio_features, text_features], axis=1)

        # 5æŠ˜äº¤å‰éªŒè¯
        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
        predictions = np.zeros(len(labels))
        fold_scores = []

        for fold, (train_idx, val_idx) in enumerate(kf.split(combined_features, labels)):
            X_train, X_val = combined_features[train_idx], combined_features[val_idx]
            y_train, y_val = labels[train_idx], labels[val_idx]

            model = lgb.LGBMClassifier(
                n_estimators=1000,
                learning_rate=0.05,
                num_leaves=31,
                random_state=SEED,
                verbose=-1
            )
            model.fit(X_train, y_train)
            fold_pred = model.predict(X_val)
            predictions[val_idx] = fold_pred

            fold_accuracy = accuracy_score(y_val, fold_pred)
            fold_scores.append(fold_accuracy)

        accuracy = accuracy_score(labels, predictions)
        print(f"  LightGBM Accuracy: {accuracy:.4f}")

        return predictions, model, fold_scores

    def _train_random_forest(self, audio_features, text_features, labels):
        """è®­ç»ƒéšæœºæ£®æž—æ¨¡åž‹"""
        combined_features = np.concatenate([audio_features, text_features], axis=1)

        # 5æŠ˜äº¤å‰éªŒè¯
        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
        predictions = np.zeros(len(labels))
        fold_scores = []

        for fold, (train_idx, val_idx) in enumerate(kf.split(combined_features, labels)):
            X_train, X_val = combined_features[train_idx], combined_features[val_idx]
            y_train, y_val = labels[train_idx], labels[val_idx]

            model = RandomForestClassifier(
                n_estimators=500,
                max_depth=10,
                min_samples_split=5,
                random_state=SEED,
                n_jobs=-1
            )
            model.fit(X_train, y_train)
            fold_pred = model.predict(X_val)
            predictions[val_idx] = fold_pred

            fold_accuracy = accuracy_score(y_val, fold_pred)
            fold_scores.append(fold_accuracy)

        accuracy = accuracy_score(labels, predictions)
        print(f"  Random Forest Accuracy: {accuracy:.4f}")

        return predictions, model, fold_scores

    def _train_gradient_boosting(self, audio_features, text_features, labels):
        """è®­ç»ƒæ¢¯åº¦æå‡æ¨¡åž‹"""
        combined_features = np.concatenate([audio_features, text_features], axis=1)

        # 5æŠ˜äº¤å‰éªŒè¯
        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
        predictions = np.zeros(len(labels))
        fold_scores = []

        for fold, (train_idx, val_idx) in enumerate(kf.split(combined_features, labels)):
            X_train, X_val = combined_features[train_idx], combined_features[val_idx]
            y_train, y_val = labels[train_idx], labels[val_idx]

            model = GradientBoostingClassifier(
                n_estimators=500,
                learning_rate=0.05,
                max_depth=6,
                random_state=SEED
            )
            model.fit(X_train, y_train)
            fold_pred = model.predict(X_val)
            predictions[val_idx] = fold_pred

            fold_accuracy = accuracy_score(y_val, fold_pred)
            fold_scores.append(fold_accuracy)

        accuracy = accuracy_score(labels, predictions)
        print(f"  Gradient Boosting Accuracy: {accuracy:.4f}")

        return predictions, model, fold_scores

    def _ensemble_predictions(self, true_labels):
        """é›†æˆé¢„æµ‹"""
        all_predictions = list(self.predictions.values())

        # åŠ æƒæŠ•ç¥¨
        final_predictions = []
        for i in range(len(true_labels)):
            votes = [pred[i] for pred in all_predictions]
            final_predictions.append(np.argmax(np.bincount(votes)))

        accuracy = accuracy_score(true_labels, final_predictions)
        print(f"  Ensemble Model Accuracy: {accuracy:.4f}")

        return np.array(final_predictions)

# ========================== å¢žå¼ºå¯è§†åŒ–ç³»ç»Ÿ ==========================
class EnhancedVisualization:
    """å¢žå¼ºå¯è§†åŒ–ç³»ç»Ÿ - è‹±æ–‡æ ‡ç­¾æ˜¾ç¤º"""

    def __init__(self, feature_engineer):
        self.feature_engineer = feature_engineer
        self.class_names = feature_engineer.label_encoder.classes_

    def plot_comprehensive_training_analysis(self, training_system, ensemble_predictions, true_labels):
        """ç»˜åˆ¶å…¨é¢çš„è®­ç»ƒåˆ†æžå›¾"""
        print("\n=== Generating Comprehensive Training Analysis ===")

        # åˆ›å»ºç»¼åˆå›¾è¡¨
        fig = plt.figure(figsize=(25, 20))

        # 1. æ·±åº¦å­¦ä¹ è®­ç»ƒåŽ†å²ï¼ˆè¯¦ç»†ï¼‰
        ax1 = plt.subplot2grid((4, 4), (0, 0), colspan=2)
        self._plot_detailed_training_history(ax1, training_system)

        # 2. æ¨¡åž‹æ€§èƒ½å¯¹æ¯”
        ax2 = plt.subplot2grid((4, 4), (0, 2), colspan=2)
        self._plot_model_comparison(ax2, training_system, true_labels, ensemble_predictions)

        # 3. é›†æˆæ¨¡åž‹æ··æ·†çŸ©é˜µ
        ax3 = plt.subplot2grid((4, 4), (1, 0))
        self._plot_confusion_matrix(ax3, ensemble_predictions, true_labels, "Ensemble Model")

        # 4. äº¤å‰éªŒè¯åˆ†æ•°çƒ­åŠ›å›¾
        ax4 = plt.subplot2grid((4, 4), (1, 1))
        self._plot_cv_heatmap(ax4, training_system)

        # 5. å­¦ä¹ çŽ‡å’Œæ¢¯åº¦å˜åŒ–
        ax5 = plt.subplot2grid((4, 4), (1, 2))
        self._plot_learning_rate_gradient(ax5, training_system)

        # 6. æ¨¡åž‹é¢„æµ‹ç›¸å…³æ€§
        ax6 = plt.subplot2grid((4, 4), (1, 3))
        self._plot_predictions_correlation(ax6, training_system, true_labels)

        # 7. è¯¦ç»†æ€§èƒ½æŒ‡æ ‡
        ax7 = plt.subplot2grid((4, 4), (2, 0), colspan=4)
        self._plot_detailed_metrics(ax7, training_system, true_labels, ensemble_predictions)

        # 8. è®­ç»ƒåŠ¨æ€åˆ†æž
        ax8 = plt.subplot2grid((4, 4), (3, 0), colspan=2)
        self._plot_training_dynamics(ax8, training_system)

        # 9. ç±»åˆ«æ€§èƒ½åˆ†æž
        ax9 = plt.subplot2grid((4, 4), (3, 2), colspan=2)
        self._plot_class_performance(ax9, ensemble_predictions, true_labels)

        plt.tight_layout()
        plt.savefig(result_folder_path + 'comprehensive_training_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()

        # é¢å¤–ç»˜åˆ¶ä¸ªä½“æ¨¡åž‹æ··æ·†çŸ©é˜µ
        self._plot_individual_model_confusions(training_system, true_labels)

        # è®­ç»ƒè¿‡ç¨‹åŠ¨ç”»å¼å¯è§†åŒ–
        self._plot_training_progression(training_system)

    def _plot_detailed_training_history(self, ax, training_system):
        """ç»˜åˆ¶è¯¦ç»†è®­ç»ƒåŽ†å²"""
        if 'Deep Learning' in training_system.training_histories:
            history = training_system.training_histories['Deep Learning']
            epochs = range(len(history['train_loss']))

            # æŸå¤±æ›²çº¿
            ax.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2, alpha=0.8)
            ax.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2, alpha=0.8)
            ax.set_xlabel('Epochs')
            ax.set_ylabel('Loss', color='black')
            ax.set_title('Deep Learning Training History\nLoss Curves', fontsize=12, fontweight='bold')
            ax.legend(loc='upper left')
            ax.grid(True, alpha=0.3)

            # å‡†ç¡®çŽ‡æ›²çº¿ï¼ˆåŒYè½´ï¼‰
            ax2 = ax.twinx()
            ax2.plot(epochs, history['train_acc'], 'b--', label='Training Accuracy', linewidth=2, alpha=0.7)
            ax2.plot(epochs, history['val_acc'], 'r--', label='Validation Accuracy', linewidth=2, alpha=0.7)
            ax2.set_ylabel('Accuracy', color='black')
            ax2.legend(loc='upper right')
            ax2.set_ylim(0, 1)

            # æ ‡è®°æœ€ä½³epoch
            best_epoch = np.argmax(history['val_acc'])
            best_val_acc = history['val_acc'][best_epoch]
            ax2.axvline(x=best_epoch, color='green', linestyle=':', alpha=0.7, label=f'Best Epoch: {best_epoch}')
            ax2.legend(loc='upper right')
        else:
            ax.text(0.5, 0.5, 'No Training History Available', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Deep Learning Training History', fontsize=12, fontweight='bold')

    def _plot_model_comparison(self, ax, training_system, true_labels, ensemble_predictions):
        """ç»˜åˆ¶æ¨¡åž‹æ€§èƒ½å¯¹æ¯”"""
        model_names = []
        accuracies = []
        f1_scores = []

        for model_name, predictions in training_system.predictions.items():
            accuracy = accuracy_score(true_labels, predictions)
            f1 = f1_score(true_labels, predictions, average='weighted')

            model_names.append(model_name)
            accuracies.append(accuracy)
            f1_scores.append(f1)

        # æ·»åŠ é›†æˆæ¨¡åž‹
        ensemble_accuracy = accuracy_score(true_labels, ensemble_predictions)
        ensemble_f1 = f1_score(true_labels, ensemble_predictions, average='weighted')

        model_names.append('Ensemble')
        accuracies.append(ensemble_accuracy)
        f1_scores.append(ensemble_f1)

        x = np.arange(len(model_names))
        width = 0.35

        bars1 = ax.bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue', edgecolor='black')
        bars2 = ax.bar(x + width/2, f1_scores, width, label='F1-Score', alpha=0.8, color='lightcoral', edgecolor='black')

        ax.set_xlabel('Models')
        ax.set_ylabel('Scores')
        ax.set_title('Model Performance Comparison\n(Accuracy vs F1-Score)', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(model_names, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)

        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2, height + 0.01,
                       f'{height:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')

    def _plot_confusion_matrix(self, ax, predictions, true_labels, title):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾"""
        cm = confusion_matrix(true_labels, predictions)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                   xticklabels=self.class_names,
                   yticklabels=self.class_names,
                   cbar_kws={'label': 'Count'})
        ax.set_xlabel('Predicted Labels', fontweight='bold')
        ax.set_ylabel('True Labels', fontweight='bold')
        ax.set_title(f'Confusion Matrix\n{title}', fontsize=12, fontweight='bold')

    def _plot_cv_heatmap(self, ax, training_system):
        """ç»˜åˆ¶äº¤å‰éªŒè¯åˆ†æ•°çƒ­åŠ›å›¾"""
        cv_data = []
        model_names = []

        for model_name, scores in training_system.model_performances.items():
            if scores:  # åªåŒ…å«æœ‰CVåˆ†æ•°çš„æ¨¡åž‹
                cv_data.append(scores)
                model_names.append(model_name)

        if cv_data:
            cv_array = np.array(cv_data)
            sns.heatmap(cv_array, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax,
                       xticklabels=[f'Fold {i+1}' for i in range(cv_array.shape[1])],
                       yticklabels=model_names,
                       cbar_kws={'label': 'Accuracy'})
            ax.set_xlabel('Cross-Validation Folds', fontweight='bold')
            ax.set_ylabel('Models', fontweight='bold')
            ax.set_title('Cross-Validation Scores\n(5-Fold CV)', fontsize=12, fontweight='bold')
        else:
            ax.text(0.5, 0.5, 'No CV Scores Available', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Cross-Validation Scores', fontsize=12, fontweight='bold')

    def _plot_learning_rate_gradient(self, ax, training_system):
        """ç»˜åˆ¶å­¦ä¹ çŽ‡å’Œæ¢¯åº¦å˜åŒ–"""
        if 'Deep Learning' in training_system.epoch_details:
            details = training_system.epoch_details['Deep Learning']
            epochs = details['epochs']

            # å­¦ä¹ çŽ‡æ›²çº¿
            ax.plot(epochs, details['learning_rate'], 'g-', label='Learning Rate', linewidth=2)
            ax.set_xlabel('Epochs')
            ax.set_ylabel('Learning Rate', color='green')
            ax.tick_params(axis='y', labelcolor='green')
            ax.set_title('Learning Rate and Gradient Norm', fontsize=12, fontweight='bold')
            ax.grid(True, alpha=0.3)

            # æ¢¯åº¦èŒƒæ•°æ›²çº¿ï¼ˆåŒYè½´ï¼‰
            ax2 = ax.twinx()
            ax2.plot(epochs, details['grad_norm'], 'purple', label='Gradient Norm', linewidth=2, alpha=0.7)
            ax2.set_ylabel('Gradient Norm', color='purple')
            ax2.tick_params(axis='y', labelcolor='purple')

            # ç»„åˆå›¾ä¾‹
            lines1, labels1 = ax.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
        else:
            ax.text(0.5, 0.5, 'No Training Details Available', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Learning Rate and Gradient', fontsize=12, fontweight='bold')

    def _plot_predictions_correlation(self, ax, training_system, true_labels):
        """ç»˜åˆ¶æ¨¡åž‹é¢„æµ‹ç›¸å…³æ€§çƒ­åŠ›å›¾"""
        model_names = list(training_system.predictions.keys())
        n_models = len(model_names)

        if n_models > 1:
            corr_matrix = np.ones((n_models, n_models))

            for i in range(n_models):
                for j in range(n_models):
                    if i != j:
                        corr = np.corrcoef(training_system.predictions[model_names[i]], 
                                         training_system.predictions[model_names[j]])[0, 1]
                        corr_matrix[i, j] = corr

            sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', 
                       center=0, ax=ax, square=True,
                       xticklabels=model_names, yticklabels=model_names,
                       cbar_kws={'label': 'Correlation'})
            ax.set_title('Model Predictions Correlation', fontsize=12, fontweight='bold')
        else:
            ax.text(0.5, 0.5, 'Need Multiple Models\nfor Correlation Analysis', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Model Predictions Correlation', fontsize=12, fontweight='bold')

    def _plot_detailed_metrics(self, ax, training_system, true_labels, ensemble_predictions):
        """ç»˜åˆ¶è¯¦ç»†æ€§èƒ½æŒ‡æ ‡"""
        metrics_data = []
        model_names = list(training_system.predictions.keys()) + ['Ensemble']

        for model_name in model_names:
            if model_name == 'Ensemble':
                predictions = ensemble_predictions
            else:
                predictions = training_system.predictions[model_name]

            accuracy = accuracy_score(true_labels, predictions)
            precision = precision_score(true_labels, predictions, average='weighted')
            recall = recall_score(true_labels, predictions, average='weighted')
            f1 = f1_score(true_labels, predictions, average='weighted')

            metrics_data.append([accuracy, precision, recall, f1])

        metrics_array = np.array(metrics_data)
        metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

        x = np.arange(len(model_names))
        width = 0.2

        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']

        for i, metric in enumerate(metrics_names):
            bars = ax.bar(x + i*width, metrics_array[:, i], width, label=metric, color=colors[i], alpha=0.8, edgecolor='black')

            # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
            for bar, value in zip(bars, metrics_array[:, i]):
                ax.text(bar.get_x() + bar.get_width()/2, value + 0.01, f'{value:.3f}', 
                       ha='center', va='bottom', fontsize=8, rotation=45)

        ax.set_xlabel('Models', fontweight='bold')
        ax.set_ylabel('Scores', fontweight='bold')
        ax.set_title('Detailed Performance Metrics by Model', fontsize=14, fontweight='bold')
        ax.set_xticks(x + width*1.5)
        ax.set_xticklabels(model_names, rotation=45, ha='right')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)

    def _plot_training_dynamics(self, ax, training_system):
        """ç»˜åˆ¶è®­ç»ƒåŠ¨æ€åˆ†æž"""
        if 'Deep Learning' in training_system.epoch_details:
            details = training_system.epoch_details['Deep Learning']
            epochs = details['epochs']

            # è®¡ç®—è®­ç»ƒå’ŒéªŒè¯å·®è·
            gap = np.array(details['train_acc']) - np.array(details['val_acc'])

            ax.plot(epochs, gap, 'orange', linewidth=2, label='Train-Val Gap')
            ax.axhline(y=0, color='red', linestyle='--', alpha=0.7, label='Zero Gap')
            ax.fill_between(epochs, gap, alpha=0.3, color='orange')

            ax.set_xlabel('Epochs')
            ax.set_ylabel('Accuracy Gap')
            ax.set_title('Training Dynamics\n(Train-Validation Gap)', fontsize=12, fontweight='bold')
            ax.legend()
            ax.grid(True, alpha=0.3)

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            avg_gap = np.mean(gap)
            max_gap = np.max(gap)
            ax.text(0.02, 0.98, f'Avg Gap: {avg_gap:.3f}\nMax Gap: {max_gap:.3f}', 
                   transform=ax.transAxes, va='top', ha='left', 
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        else:
            ax.text(0.5, 0.5, 'No Training Dynamics Data', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Training Dynamics', fontsize=12, fontweight='bold')

    def _plot_class_performance(self, ax, predictions, true_labels):
        """ç»˜åˆ¶ç±»åˆ«æ€§èƒ½åˆ†æž"""
        class_performance = []
        precision_scores = []
        recall_scores = []

        for class_idx, class_name in enumerate(self.class_names):
            class_mask = (true_labels == class_idx)
            if np.sum(class_mask) > 0:  # ç¡®ä¿æœ‰æ ·æœ¬
                class_accuracy = accuracy_score(true_labels[class_mask], predictions[class_mask])
                class_precision = precision_score(true_labels, predictions, average=None, labels=[class_idx])[0]
                class_recall = recall_score(true_labels, predictions, average=None, labels=[class_idx])[0]

                class_performance.append(class_accuracy)
                precision_scores.append(class_precision)
                recall_scores.append(class_recall)

        x = np.arange(len(self.class_names))
        width = 0.25

        ax.bar(x - width, class_performance, width, label='Accuracy', alpha=0.8, color='lightblue')
        ax.bar(x, precision_scores, width, label='Precision', alpha=0.8, color='lightcoral')
        ax.bar(x + width, recall_scores, width, label='Recall', alpha=0.8, color='lightgreen')

        ax.set_xlabel('Classes')
        ax.set_ylabel('Scores')
        ax.set_title('Class-wise Performance Analysis\n(Ensemble Model)', fontsize=12, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(self.class_names)
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (acc, prec, rec) in enumerate(zip(class_performance, precision_scores, recall_scores)):
            ax.text(i - width, acc + 0.02, f'{acc:.2f}', ha='center', va='bottom', fontsize=8)
            ax.text(i, prec + 0.02, f'{prec:.2f}', ha='center', va='bottom', fontsize=8)
            ax.text(i + width, rec + 0.02, f'{rec:.2f}', ha='center', va='bottom', fontsize=8)

    def _plot_individual_model_confusions(self, training_system, true_labels):
        """ç»˜åˆ¶ä¸ªä½“æ¨¡åž‹æ··æ·†çŸ©é˜µ"""
        n_models = len(training_system.predictions)
        if n_models > 0:
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            axes = axes.ravel()

            for idx, (model_name, predictions) in enumerate(training_system.predictions.items()):
                if idx < 4:  # é™åˆ¶ä¸º4ä¸ªå­å›¾
                    cm = confusion_matrix(true_labels, predictions)
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],
                               xticklabels=self.class_names,
                               yticklabels=self.class_names)
                    accuracy = accuracy_score(true_labels, predictions)
                    axes[idx].set_title(f'{model_name}\nAccuracy: {accuracy:.3f}', fontweight='bold')
                    axes[idx].set_xlabel('Predicted')
                    axes[idx].set_ylabel('True')

            # éšè—æœªä½¿ç”¨çš„å­å›¾
            for idx in range(n_models, 4):
                axes[idx].set_visible(False)

            plt.tight_layout()
            plt.savefig(result_folder_path + 'individual_model_confusions.png', dpi=300, bbox_inches='tight')
            plt.show()

    def _plot_training_progression(self, training_system):
        """ç»˜åˆ¶è®­ç»ƒè¿›åº¦å¯è§†åŒ–"""
        if 'Deep Learning' in training_system.epoch_details:
            details = training_system.epoch_details['Deep Learning']
            epochs = details['epochs']

            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

            # è®­ç»ƒè¿›åº¦ - æŸå¤±
            ax1.plot(epochs, details['train_loss'], 'b-', label='Training Loss', linewidth=2)
            ax1.plot(epochs, details['val_loss'], 'r-', label='Validation Loss', linewidth=2)
            ax1.set_xlabel('Epochs')
            ax1.set_ylabel('Loss')
            ax1.set_title('Training Progression - Loss', fontweight='bold')
            ax1.legend()
            ax1.grid(True, alpha=0.3)

            # è®­ç»ƒè¿›åº¦ - å‡†ç¡®çŽ‡
            ax2.plot(epochs, details['train_acc'], 'b-', label='Training Accuracy', linewidth=2)
            ax2.plot(epochs, details['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)
            ax2.set_xlabel('Epochs')
            ax2.set_ylabel('Accuracy')
            ax2.set_title('Training Progression - Accuracy', fontweight='bold')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            ax2.set_ylim(0, 1)

            plt.tight_layout()
            plt.savefig(result_folder_path + 'training_progression.png', dpi=300, bbox_inches='tight')
            plt.show()

# ========================== ä¸»å‡½æ•° ==========================
def main():
    print("Alzheimer's Disease Multimodal Recognition System - Complete Visualization")
    print("=" * 70)

    try:
        # 1. çœŸå®žæ•°æ®å¤„ç†
        processor = RealDataProcessor()
        merged_data = processor.process_all_data()

        # 2. ç‰¹å¾å·¥ç¨‹
        feature_engineer = EnhancedFeatureEngineering()
        audio_features, text_features, labels = feature_engineer.prepare_features(merged_data)

        print(f"\n=== Data Summary ===")
        print(f"Training samples: {len(labels)}")
        print(f"Audio features: {audio_features.shape}")
        print(f"Text features: {text_features.shape}")
        label_distribution = dict(zip(feature_engineer.label_encoder.classes_, np.bincount(labels)))
        print(f"Label distribution: {label_distribution}")

        # 3. è®­ç»ƒå¢žå¼ºç³»ç»Ÿ
        training_system = EnhancedTrainingSystem()
        ensemble_predictions = training_system.train_enhanced_system(
            audio_features, text_features, labels, feature_engineer
        )

        # 4. æœ€ç»ˆè¯„ä¼°
        print("\n=== Final Performance Evaluation ===")
        accuracy = accuracy_score(labels, ensemble_predictions)
        f1 = f1_score(labels, ensemble_predictions, average='weighted')

        print(f"Ensemble System Accuracy: {accuracy:.4f}")
        print(f"Ensemble System F1 Score: {f1:.4f}")
        print("\nDetailed Classification Report:")
        print(classification_report(labels, ensemble_predictions, 
                                  target_names=feature_engineer.label_encoder.classes_))

        # 5. æ€§èƒ½è¯„ä¼°
        if accuracy >= 0.85:
            print("ðŸŽ‰ Outstanding! System achieved top performance!")
        elif accuracy >= 0.75:
            print("âœ… Excellent! Robust performance achieved!")
        elif accuracy >= 0.65:
            print("âš ï¸ Good performance, consider further optimization")
        else:
            print("âŒ Needs improvement")

        # 6. ç»¼åˆå¯è§†åŒ–
        visualizer = EnhancedVisualization(feature_engineer)
        visualizer.plot_comprehensive_training_analysis(training_system, ensemble_predictions, labels)

        # 7. ä¿å­˜æ¨¡åž‹
        torch.save({
            'training_system': training_system,
            'feature_engineer': feature_engineer,
            'accuracy': accuracy,
            'model_state_dict': training_system.models['Deep Learning'].state_dict() if 'Deep Learning' in training_system.models else None
        }, 'complete_alzheimer_system.pth')

        print(f"\nModel saved: complete_alzheimer_system.pth")

        print("\n" + "="*50)
        print("System training and visualization completed!")
        print("Ready for deployment.")
        print("="*50)

    except Exception as e:
        print(f"Runtime error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()


# In[3]:


# -*- coding: utf-8 -*-
"""
é˜¿å°”èŒ¨æµ·é»˜ç—‡å¤šæ¨¡æ€è¯†åˆ«ç³»ç»Ÿ - å®Œæ•´å¯è§†åŒ–ç‰ˆ
é›†æˆè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ï¼Œä¸­æ–‡æ³¨é‡Šï¼Œè‹±æ–‡æ ‡ç­¾æ˜¾ç¤º
"""

import os
import pandas as pd
import numpy as np
import time
from tqdm import tqdm
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import (roc_auc_score, recall_score, f1_score, 
                           accuracy_score, classification_report, 
                           confusion_matrix, precision_score)
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
import torch.nn.functional as F
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®
plt.rcParams['font.size'] = 12
plt.rcParams['font.family'] = 'DejaVu Sans'
sns.set_style("whitegrid")

SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# ========================== çœŸå®žæ•°æ®å¤„ç†å™¨ ==========================
class RealDataProcessor:
    """çœŸå®žæ•°æ®å¤„ç†å™¨ - åŸºäºŽå®žé™…æ•°æ®ç»“æž„"""

    def __init__(self, base_path='./kaggle/input/alzheimer/data/'):
        self.base_path = base_path
        self.egemaps_pre_path = os.path.join(base_path, 'egemaps_final.csv')
        self.train_list_path = os.path.join(base_path, '2_final_list_train.csv')
        self.test_list_path = os.path.join(base_path, '2_final_list_test.csv')
        self.tsv_dir = os.path.join(base_path, 'tsv2/')
        self.egemaps_dir = '/data/egemaps2/'  # æ ¹æ®å®žé™…æƒ…å†µæ›´æ–°è·¯å¾„

    def process_all_data(self):
        """å¤„ç†æ‰€æœ‰æ•°æ®"""
        print("=== Processing Real Alzheimer's Disease Data ===")

        # 1. åŠ è½½åŸºç¡€æ•°æ®
        print("1. Loading basic data...")
        preliminary_list_test = pd.read_csv(self.test_list_path)  # (27,2)
        preliminary_list_train = pd.read_csv(self.train_list_path)  # (179,2)
        egemaps_pre = pd.read_csv(self.egemaps_pre_path)  # (206,89)

        print(f"Training set: {preliminary_list_train.shape}")
        print(f"Test set: {preliminary_list_test.shape}")
        print(f"Precomputed features: {egemaps_pre.shape}")
        print('Training set label distribution:\n', preliminary_list_train['label'].value_counts())

        # 2. ä»ŽTSVæ–‡ä»¶æå–æ–‡æœ¬ç‰¹å¾
        print("\n2. Extracting text features from TSV files...")
        text_features = self._extract_text_features()

        # 3. ä»ŽeGeMAPSæ–‡ä»¶æå–éŸ³é¢‘ç‰¹å¾
        print("\n3. Extracting audio features from eGeMAPS files...")
        audio_features = self._extract_audio_features()

        # 4. åˆå¹¶æ‰€æœ‰ç‰¹å¾
        print("\n4. Merging all features...")
        merged_data = self._merge_all_features(
            preliminary_list_train, preliminary_list_test, 
            egemaps_pre, text_features, audio_features
        )

        return merged_data

    def _extract_text_features(self):
        """ä»ŽTSVæ–‡ä»¶æå–æ–‡æœ¬ç‰¹å¾"""
        tsv_path_lists = os.listdir(self.tsv_dir)
        tsv_feats = []

        print(f"Processing {len(tsv_path_lists)} TSV files...")

        for path in tqdm(tsv_path_lists):
            try:
                # è¯»å–tsvæ–‡ä»¶
                z = pd.read_csv(os.path.join(self.tsv_dir, path), sep='\t')
                # è®¡ç®—æ¯å¥è¯çš„æ—¶é•¿
                z['end_time-start_time'] = z['end_time'] - z['start_time']

                # æå–æ—¶é•¿ç»Ÿè®¡ç‰¹å¾
                tsv_feats.append([
                    path[:-4],  # uuid
                    z['end_time-start_time'].mean(),    # å¹³å‡æ—¶é•¿
                    z['end_time-start_time'].min(),     # æœ€å°æ—¶é•¿
                    z['end_time-start_time'].max(),     # æœ€å¤§æ—¶é•¿
                    z['end_time-start_time'].std(),     # æ—¶é•¿æ ‡å‡†å·®
                    z['end_time-start_time'].median(),  # æ—¶é•¿ä¸­ä½æ•°
                    z['end_time-start_time'].skew(),    # æ—¶é•¿ååº¦
                    z.shape[0]                         # å¥å­æ•°é‡
                ])
            except Exception as e:
                print(f"Error processing file {path}: {e}")
                continue

        # è½¬æ¢ä¸ºDataFrame
        tsv_feats_df = pd.DataFrame(tsv_feats)
        tsv_feats_df.columns = ['uuid'] + [f'text_feat_{i}' for i in range(tsv_feats_df.shape[1] - 1)]

        print(f"Text features extracted: {tsv_feats_df.shape}")
        return tsv_feats_df

    def _extract_audio_features(self):
        """ä»ŽeGeMAPSæ–‡ä»¶æå–éŸ³é¢‘ç‰¹å¾"""
        try:
            egemaps_path_lists = os.listdir(self.egemaps_dir)
        except:
            print(f"eGeMAPS directory not found: {self.egemaps_dir}")
            return None

        egemaps_feats = []

        print(f"Processing {len(egemaps_path_lists)} eGeMAPS files...")

        for path in tqdm(egemaps_path_lists):
            try:
                # è¯»å–æ–‡ä»¶ï¼ˆåˆ†éš”ç¬¦æ˜¯;ï¼‰
                z = pd.read_csv(os.path.join(self.egemaps_dir, path), sep=';')
                # ç§»é™¤nameåˆ—
                if 'name' in z.columns:
                    z = z.drop(['name'], axis=1)

                # æå–æ¯åˆ—çš„ç»Ÿè®¡ç‰¹å¾
                feature_vector = [path[:-4]]  # uuid

                # å‡å€¼ã€æ ‡å‡†å·®ã€æœ€å°å€¼ã€ä¸­ä½æ•°
                feature_vector.extend(list(z.mean(axis=0)))    # å‡å€¼
                feature_vector.extend(list(z.std(axis=0)))     # æ ‡å‡†å·®
                feature_vector.extend(list(z.min(axis=0)))     # æœ€å°å€¼
                feature_vector.extend(list(z.median(axis=0)))  # ä¸­ä½æ•°

                egemaps_feats.append(feature_vector)

            except Exception as e:
                print(f"Error processing audio file {path}: {e}")
                continue

        if egemaps_feats:
            # è½¬æ¢ä¸ºDataFrame
            egemaps_feats_df = pd.DataFrame(egemaps_feats)
            n_features = (egemaps_feats_df.shape[1] - 1) // 4
            columns = ['uuid']

            # åˆ›å»ºæè¿°æ€§åˆ—å
            for stat in ['mean', 'std', 'min', 'median']:
                for i in range(n_features):
                    columns.append(f'audio_{stat}_{i:03d}')

            egemaps_feats_df.columns = columns[:egemaps_feats_df.shape[1]]
            print(f"Audio features extracted: {egemaps_feats_df.shape}")
            return egemaps_feats_df
        else:
            return None

    def _merge_all_features(self, train_list, test_list, egemaps_pre, text_features, audio_features):
        """åˆå¹¶æ‰€æœ‰ç‰¹å¾"""
        print("Merging features...")

        # åˆå¹¶è®­ç»ƒå’Œæµ‹è¯•é›†
        all_data = pd.concat([train_list, test_list], ignore_index=True)
        print(f"Combined data: {all_data.shape}")

        # ç¡®ä¿uuidåˆ—ç±»åž‹ä¸€è‡´
        all_data['uuid'] = all_data['uuid'].astype(str)
        egemaps_pre['uuid'] = egemaps_pre['uuid'].astype(str)
        text_features['uuid'] = text_features['uuid'].astype(str)

        # åˆå¹¶é¢„è®¡ç®—çš„eGeMAPSç‰¹å¾
        merged_data = pd.merge(all_data, egemaps_pre, on='uuid', how='left')
        print(f"After eGeMAPS merge: {merged_data.shape}")

        # åˆå¹¶æ–‡æœ¬ç‰¹å¾
        merged_data = pd.merge(merged_data, text_features, on='uuid', how='left')
        print(f"After text features merge: {merged_data.shape}")

        # åˆå¹¶éŸ³é¢‘ç‰¹å¾ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if audio_features is not None:
            audio_features['uuid'] = audio_features['uuid'].astype(str)
            merged_data = pd.merge(merged_data, audio_features, on='uuid', how='left')
            print(f"After audio features merge: {merged_data.shape}")

        # æ•°æ®æ¸…æ´—
        merged_data = self._clean_data(merged_data)

        print(f"Final merged data shape: {merged_data.shape}")
        print("Label distribution in final data:")
        print(merged_data['label'].value_counts())

        return merged_data

    def _clean_data(self, data):
        """æ¸…æ´—å’Œé¢„å¤„ç†æ•°æ®"""
        # ç§»é™¤ç¼ºå¤±æ ‡ç­¾çš„è¡Œ
        data = data[data['label'].notna()]
        data = data[data['label'] != '']
        data = data[data['label'] != 'nan']

        # æ ‡å‡†åŒ–æ ‡ç­¾
        data['label'] = data['label'].astype(str).str.upper().str.strip()

        # å¡«å……ç‰¹å¾åˆ—çš„ç¼ºå¤±å€¼
        feature_columns = [col for col in data.columns if col not in ['uuid', 'label', 'sex', 'age', 'education']]
        data[feature_columns] = data[feature_columns].fillna(data[feature_columns].mean())

        return data

# ========================== å¢žå¼ºç‰¹å¾å·¥ç¨‹ ==========================
class EnhancedFeatureEngineering:
    """å¢žå¼ºç‰¹å¾å·¥ç¨‹"""

    def __init__(self):
        self.scaler_audio = StandardScaler()
        self.scaler_text = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.audio_columns = None
        self.text_columns = None
        self.selected_audio_columns = None
        self.selected_text_columns = None

    def prepare_features(self, data):
        """å‡†å¤‡ç‰¹å¾ç”¨äºŽæ¨¡åž‹è®­ç»ƒ"""
        print("\n=== Feature Engineering ===")

        # ç¼–ç æ ‡ç­¾
        labels = self.label_encoder.fit_transform(data['label'])
        label_mapping = dict(zip(self.label_encoder.classes_, range(len(self.label_encoder.classes_))))
        print(f"Label encoding: {label_mapping}")

        # è¯†åˆ«ç‰¹å¾åˆ—
        feature_columns = [col for col in data.columns if col not in ['uuid', 'label', 'sex', 'age', 'education']]

        # åˆ†ç¦»éŸ³é¢‘å’Œæ–‡æœ¬ç‰¹å¾
        self.audio_columns = [col for col in feature_columns if any(keyword in col.lower() for keyword in 
                            ['f0', 'rms', 'mfcc', 'spectral', 'energy', 'loudness', 'jitter', 'shimmer', 'hnr', 'audio'])]
        self.text_columns = [col for col in feature_columns if any(keyword in col.lower() for keyword in 
                           ['text_feat', 'duration', 'sentence'])]

        # å¦‚æžœè‡ªåŠ¨æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨æ‰‹åŠ¨åˆ†é…
        if not self.audio_columns:
            # å‡è®¾å‰88åˆ—æ˜¯éŸ³é¢‘ç‰¹å¾
            self.audio_columns = feature_columns[:88]
        if not self.text_columns:
            # å‰©ä½™åˆ—æ˜¯æ–‡æœ¬ç‰¹å¾
            self.text_columns = [col for col in feature_columns if col not in self.audio_columns]

        print(f"Audio features identified: {len(self.audio_columns)}")
        print(f"Text features identified: {len(self.text_columns)}")

        # ç‰¹å¾é€‰æ‹©
        selected_audio, selected_text = self._select_features(
            data[self.audio_columns], data[self.text_columns], labels
        )

        # æ ‡å‡†åŒ–
        audio_features = self.scaler_audio.fit_transform(selected_audio)
        text_features = self.scaler_text.fit_transform(selected_text)

        print(f"Final feature dimensions - Audio: {audio_features.shape}, Text: {text_features.shape}")

        return audio_features, text_features, labels

    def _select_features(self, audio_data, text_data, labels):
        """é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾"""
        print("Performing feature selection...")

        # éŸ³é¢‘ç‰¹å¾é€‰æ‹©
        if audio_data.shape[1] > 50:
            selector_audio = SelectKBest(f_classif, k=min(50, audio_data.shape[1]))
            audio_selected = selector_audio.fit_transform(audio_data, labels)
            self.selected_audio_columns = [self.audio_columns[i] for i in selector_audio.get_support(indices=True)]
            print(f"Selected {len(self.selected_audio_columns)} audio features")
        else:
            audio_selected = audio_data.values
            self.selected_audio_columns = self.audio_columns

        # æ–‡æœ¬ç‰¹å¾é€‰æ‹©
        if text_data.shape[1] > 15:
            selector_text = SelectKBest(f_classif, k=min(15, text_data.shape[1]))
            text_selected = selector_text.fit_transform(text_data, labels)
            self.selected_text_columns = [self.text_columns[i] for i in selector_text.get_support(indices=True)]
            print(f"Selected {len(self.selected_text_columns)} text features")
        else:
            text_selected = text_data.values
            self.selected_text_columns = self.text_columns

        return audio_selected, text_selected

# ========================== ç¨³å®šæ¨¡åž‹æž¶æž„ ==========================
class StableAlzheimerNet(nn.Module):
    """ç¨³å®šçš„é˜¿å°”èŒ¨æµ·é»˜ç—‡è¯†åˆ«ç½‘ç»œ"""

    def __init__(self, audio_dim, text_dim, num_classes=3):
        super(StableAlzheimerNet, self).__init__()

        # éŸ³é¢‘ç¼–ç å™¨
        self.audio_encoder = nn.Sequential(
            nn.Linear(audio_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
        )

        # æ–‡æœ¬ç¼–ç å™¨
        self.text_encoder = nn.Sequential(
            nn.Linear(text_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
        )

        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(64 + 32, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, num_classes)
        )

    def forward(self, audio_features, text_features):
        audio_encoded = self.audio_encoder(audio_features)
        text_encoded = self.text_encoder(text_features)

        # æ‹¼æŽ¥ç‰¹å¾
        combined = torch.cat([audio_encoded, text_encoded], dim=1)
        output = self.classifier(combined)

        return output

# ========================== å¢žå¼ºè®­ç»ƒç³»ç»Ÿï¼ˆå¸¦è¯¦ç»†å¯è§†åŒ–ï¼‰ ==========================
class EnhancedTrainingSystem:
    """å¢žå¼ºè®­ç»ƒç³»ç»Ÿ - å¸¦è¯¦ç»†è®­ç»ƒè¿‡ç¨‹è·Ÿè¸ªå’Œå¯è§†åŒ–"""

    def __init__(self):
        self.models = {}
        self.predictions = {}
        self.training_histories = {}
        self.model_performances = {}
        self.epoch_details = {}  # å­˜å‚¨æ¯ä¸ªepochçš„è¯¦ç»†ä¿¡æ¯

    def train_enhanced_system(self, audio_features, text_features, labels, feature_engineer):
        """è®­ç»ƒå¢žå¼ºç³»ç»Ÿ"""
        print("\n=== Training Enhanced System ===")

        # 1. æ·±åº¦å­¦ä¹ æ¨¡åž‹ï¼ˆä¸»è¦ç„¦ç‚¹ï¼‰
        print("1. Training Deep Learning Model...")
        dl_predictions, dl_model, dl_history, dl_epoch_details = self._train_deep_learning_with_details(
            audio_features, text_features, labels, feature_engineer
        )
        self.models['Deep Learning'] = dl_model
        self.predictions['Deep Learning'] = dl_predictions
        self.training_histories['Deep Learning'] = dl_history
        self.epoch_details['Deep Learning'] = dl_epoch_details

        # 2. LightGBMæ¨¡åž‹
        print("2. Training LightGBM Model...")
        lgb_predictions, lgb_model, lgb_scores = self._train_lightgbm(
            audio_features, text_features, labels
        )
        self.models['LightGBM'] = lgb_model
        self.predictions['LightGBM'] = lgb_predictions
        self.model_performances['LightGBM'] = lgb_scores

        # 3. éšæœºæ£®æž—æ¨¡åž‹
        print("3. Training Random Forest Model...")
        rf_predictions, rf_model, rf_scores = self._train_random_forest(
            audio_features, text_features, labels
        )
        self.models['Random Forest'] = rf_model
        self.predictions['Random Forest'] = rf_predictions
        self.model_performances['Random Forest'] = rf_scores

        # 4. æ¢¯åº¦æå‡æ¨¡åž‹
        print("4. Training Gradient Boosting Model...")
        gb_predictions, gb_model, gb_scores = self._train_gradient_boosting(
            audio_features, text_features, labels
        )
        self.models['Gradient Boosting'] = gb_model
        self.predictions['Gradient Boosting'] = gb_predictions
        self.model_performances['Gradient Boosting'] = gb_scores

        # 5. æ¨¡åž‹é›†æˆ
        print("5. Model Ensemble...")
        ensemble_predictions = self._ensemble_predictions(labels)

        return ensemble_predictions

    def _train_deep_learning_with_details(self, audio_features, text_features, labels, feature_engineer):
        """è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡åž‹ - å¸¦è¯¦ç»†è®­ç»ƒè¿‡ç¨‹è·Ÿè¸ª"""
        # æ•°æ®åˆ†å‰²
        indices = np.arange(len(labels))
        train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=SEED, stratify=labels)

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TensorDataset(
            torch.FloatTensor(audio_features[train_idx]),
            torch.FloatTensor(text_features[train_idx]),
            torch.LongTensor(labels[train_idx])
        )
        val_dataset = TensorDataset(
            torch.FloatTensor(audio_features[val_idx]),
            torch.FloatTensor(text_features[val_idx]),
            torch.LongTensor(labels[val_idx])
        )

        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

        # åˆ›å»ºæ¨¡åž‹
        model = StableAlzheimerNet(
            audio_features.shape[1],
            text_features.shape[1],
            num_classes=len(feature_engineer.label_encoder.classes_)
        ).to(device)

        # è®­ç»ƒè®¾ç½®
        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
        criterion = nn.CrossEntropyLoss()

        # è®­ç»ƒåŽ†å²è®°å½•
        train_losses = []
        val_losses = []
        train_accuracies = []
        val_accuracies = []
        learning_rates = []

        # è¯¦ç»†epochä¿¡æ¯
        epoch_details = {
            'epochs': [],
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'learning_rate': [],
            'grad_norm': []
        }

        best_val_acc = 0
        patience = 25
        no_improve = 0

        print("Deep Learning Training Progress:")
        print("Epoch | Train Loss | Val Loss | Train Acc | Val Acc | LR")
        print("-" * 60)

        for epoch in range(300):  # å¢žåŠ è®­ç»ƒè½®æ¬¡
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            epoch_train_loss = 0
            train_correct = 0
            train_total = 0
            total_grad_norm = 0

            for audio_batch, text_batch, labels_batch in train_loader:
                audio_batch, text_batch, labels_batch = (
                    audio_batch.to(device), text_batch.to(device), labels_batch.to(device)
                )

                optimizer.zero_grad()
                outputs = model(audio_batch, text_batch)
                loss = criterion(outputs, labels_batch)
                loss.backward()

                # æ¢¯åº¦è£å‰ªå’Œè®°å½•
                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                total_grad_norm += grad_norm.item()

                optimizer.step()

                epoch_train_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                train_total += labels_batch.size(0)
                train_correct += (predicted == labels_batch).sum().item()

            avg_grad_norm = total_grad_norm / len(train_loader)
            train_acc = train_correct / train_total
            train_losses.append(epoch_train_loss / len(train_loader))
            train_accuracies.append(train_acc)

            # éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss = 0
            val_correct = 0
            val_total = 0

            with torch.no_grad():
                for audio_batch, text_batch, labels_batch in val_loader:
                    audio_batch, text_batch, labels_batch = (
                        audio_batch.to(device), text_batch.to(device), labels_batch.to(device)
                    )
                    outputs = model(audio_batch, text_batch)
                    loss = criterion(outputs, labels_batch)
                    val_loss += loss.item()

                    _, predicted = torch.max(outputs.data, 1)
                    val_total += labels_batch.size(0)
                    val_correct += (predicted == labels_batch).sum().item()

            val_acc = val_correct / val_total
            val_losses.append(val_loss / len(val_loader))
            val_accuracies.append(val_acc)

            # å­¦ä¹ çŽ‡è®°å½•
            current_lr = optimizer.param_groups[0]['lr']
            learning_rates.append(current_lr)

            # è®°å½•è¯¦ç»†epochä¿¡æ¯
            epoch_details['epochs'].append(epoch)
            epoch_details['train_loss'].append(epoch_train_loss / len(train_loader))
            epoch_details['val_loss'].append(val_loss / len(val_loader))
            epoch_details['train_acc'].append(train_acc)
            epoch_details['val_acc'].append(val_acc)
            epoch_details['learning_rate'].append(current_lr)
            epoch_details['grad_norm'].append(avg_grad_norm)

            # æ¯20ä¸ªepochæ‰“å°è¿›åº¦
            if epoch % 20 == 0:
                print(f"{epoch:5d} | {epoch_train_loss/len(train_loader):10.4f} | {val_loss/len(val_loader):8.4f} | "
                      f"{train_acc:9.4f} | {val_acc:7.4f} | {current_lr:.6f}")

            # æ—©åœæ£€æŸ¥
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                no_improve = 0
                best_model_state = model.state_dict().copy()
                best_epoch = epoch
            else:
                no_improve += 1
                if no_improve >= patience:
                    print(f"Early stopping at epoch {epoch}, best validation accuracy: {best_val_acc:.4f} at epoch {best_epoch}")
                    break

        model.load_state_dict(best_model_state)

        # æœ€ç»ˆé¢„æµ‹
        model.eval()
        with torch.no_grad():
            audio_tensor = torch.FloatTensor(audio_features).to(device)
            text_tensor = torch.FloatTensor(text_features).to(device)
            outputs = model(audio_tensor, text_tensor)
            _, predictions = torch.max(outputs, 1)

        accuracy = accuracy_score(labels, predictions.cpu().numpy())
        print(f"  Deep Learning Final Accuracy: {accuracy:.4f}")

        history = {
            'train_loss': train_losses,
            'val_loss': val_losses,
            'train_acc': train_accuracies,
            'val_acc': val_accuracies,
            'learning_rates': learning_rates
        }

        return predictions.cpu().numpy(), model, history, epoch_details

    def _train_lightgbm(self, audio_features, text_features, labels):
        """è®­ç»ƒLightGBMæ¨¡åž‹"""
        combined_features = np.concatenate([audio_features, text_features], axis=1)

        # 5æŠ˜äº¤å‰éªŒè¯
        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
        predictions = np.zeros(len(labels))
        fold_scores = []

        for fold, (train_idx, val_idx) in enumerate(kf.split(combined_features, labels)):
            X_train, X_val = combined_features[train_idx], combined_features[val_idx]
            y_train, y_val = labels[train_idx], labels[val_idx]

            model = lgb.LGBMClassifier(
                n_estimators=1000,
                learning_rate=0.05,
                num_leaves=31,
                random_state=SEED,
                verbose=-1
            )
            model.fit(X_train, y_train)
            fold_pred = model.predict(X_val)
            predictions[val_idx] = fold_pred

            fold_accuracy = accuracy_score(y_val, fold_pred)
            fold_scores.append(fold_accuracy)

        accuracy = accuracy_score(labels, predictions)
        print(f"  LightGBM Accuracy: {accuracy:.4f}")

        return predictions, model, fold_scores

    def _train_random_forest(self, audio_features, text_features, labels):
        """è®­ç»ƒéšæœºæ£®æž—æ¨¡åž‹"""
        combined_features = np.concatenate([audio_features, text_features], axis=1)

        # 5æŠ˜äº¤å‰éªŒè¯
        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
        predictions = np.zeros(len(labels))
        fold_scores = []

        for fold, (train_idx, val_idx) in enumerate(kf.split(combined_features, labels)):
            X_train, X_val = combined_features[train_idx], combined_features[val_idx]
            y_train, y_val = labels[train_idx], labels[val_idx]

            model = RandomForestClassifier(
                n_estimators=500,
                max_depth=10,
                min_samples_split=5,
                random_state=SEED,
                n_jobs=-1
            )
            model.fit(X_train, y_train)
            fold_pred = model.predict(X_val)
            predictions[val_idx] = fold_pred

            fold_accuracy = accuracy_score(y_val, fold_pred)
            fold_scores.append(fold_accuracy)

        accuracy = accuracy_score(labels, predictions)
        print(f"  Random Forest Accuracy: {accuracy:.4f}")

        return predictions, model, fold_scores

    def _train_gradient_boosting(self, audio_features, text_features, labels):
        """è®­ç»ƒæ¢¯åº¦æå‡æ¨¡åž‹"""
        combined_features = np.concatenate([audio_features, text_features], axis=1)

        # 5æŠ˜äº¤å‰éªŒè¯
        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)
        predictions = np.zeros(len(labels))
        fold_scores = []

        for fold, (train_idx, val_idx) in enumerate(kf.split(combined_features, labels)):
            X_train, X_val = combined_features[train_idx], combined_features[val_idx]
            y_train, y_val = labels[train_idx], labels[val_idx]

            model = GradientBoostingClassifier(
                n_estimators=500,
                learning_rate=0.05,
                max_depth=6,
                random_state=SEED
            )
            model.fit(X_train, y_train)
            fold_pred = model.predict(X_val)
            predictions[val_idx] = fold_pred

            fold_accuracy = accuracy_score(y_val, fold_pred)
            fold_scores.append(fold_accuracy)

        accuracy = accuracy_score(labels, predictions)
        print(f"  Gradient Boosting Accuracy: {accuracy:.4f}")

        return predictions, model, fold_scores

    def _ensemble_predictions(self, true_labels):
        """é›†æˆé¢„æµ‹"""
        all_predictions = list(self.predictions.values())

        # åŠ æƒæŠ•ç¥¨
        final_predictions = []
        for i in range(len(true_labels)):
            votes = [pred[i] for pred in all_predictions]
            final_predictions.append(np.argmax(np.bincount(votes)))

        accuracy = accuracy_score(true_labels, final_predictions)
        print(f"  Ensemble Model Accuracy: {accuracy:.4f}")

        return np.array(final_predictions)

# ========================== å¢žå¼ºå¯è§†åŒ–ç³»ç»Ÿ ==========================
class EnhancedVisualization:
    """å¢žå¼ºå¯è§†åŒ–ç³»ç»Ÿ - è‹±æ–‡æ ‡ç­¾æ˜¾ç¤ºï¼Œå›¾è¡¨å•ç‹¬è¾“å‡º"""

    def __init__(self, feature_engineer):
        self.feature_engineer = feature_engineer
        self.class_names = feature_engineer.label_encoder.classes_

    def plot_comprehensive_training_analysis(self, training_system, ensemble_predictions, true_labels):
        """ç»˜åˆ¶å…¨é¢çš„è®­ç»ƒåˆ†æžå›¾ï¼Œå•ç‹¬è¾“å‡ºæ¯ä¸ªå›¾è¡¨"""
        print("\n=== Generating Comprehensive Training Analysis ===")

        # 1. æ·±åº¦å­¦ä¹ è®­ç»ƒåŽ†å²ï¼ˆè¯¦ç»†ï¼‰
        self._plot_detailed_training_history(training_system)

        # 2. æ¨¡åž‹æ€§èƒ½å¯¹æ¯”
        self._plot_model_comparison(training_system, true_labels, ensemble_predictions)

        # 3. é›†æˆæ¨¡åž‹æ··æ·†çŸ©é˜µ
        self._plot_confusion_matrix(ensemble_predictions, true_labels, "Ensemble Model")

        # 4. äº¤å‰éªŒè¯åˆ†æ•°çƒ­åŠ›å›¾
        self._plot_cv_heatmap(training_system)

        # 5. å­¦ä¹ çŽ‡å’Œæ¢¯åº¦å˜åŒ–
        self._plot_learning_rate_gradient(training_system)

        # 6. æ¨¡åž‹é¢„æµ‹ç›¸å…³æ€§
        self._plot_predictions_correlation(training_system, true_labels)

        # 7. è¯¦ç»†æ€§èƒ½æŒ‡æ ‡
        self._plot_detailed_metrics(training_system, true_labels, ensemble_predictions)

        # 8. è®­ç»ƒåŠ¨æ€åˆ†æž
        self._plot_training_dynamics(training_system)

        # 9. ç±»åˆ«æ€§èƒ½åˆ†æž
        self._plot_class_performance(ensemble_predictions, true_labels)

        # é¢å¤–ç»˜åˆ¶ä¸ªä½“æ¨¡åž‹æ··æ·†çŸ©é˜µ
        self._plot_individual_model_confusions(training_system, true_labels)

        # è®­ç»ƒè¿‡ç¨‹åŠ¨ç”»å¼å¯è§†åŒ–
        self._plot_training_progression(training_system)

    def _plot_detailed_training_history(self, training_system):
        """ç»˜åˆ¶è¯¦ç»†è®­ç»ƒåŽ†å²"""
        fig = plt.figure(figsize=(10, 6))
        ax = fig.add_subplot(111)

        if 'Deep Learning' in training_system.training_histories:
            history = training_system.training_histories['Deep Learning']
            epochs = range(len(history['train_loss']))

            # æŸå¤±æ›²çº¿
            ax.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2, alpha=0.8)
            ax.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2, alpha=0.8)
            ax.set_xlabel('Epochs')
            ax.set_ylabel('Loss', color='black')
            ax.set_title('Deep Learning Training History\nLoss Curves', fontsize=12, fontweight='bold')
            ax.legend(loc='upper left')
            ax.grid(True, alpha=0.3)

            # å‡†ç¡®çŽ‡æ›²çº¿ï¼ˆåŒYè½´ï¼‰
            ax2 = ax.twinx()
            ax2.plot(epochs, history['train_acc'], 'b--', label='Training Accuracy', linewidth=2, alpha=0.7)
            ax2.plot(epochs, history['val_acc'], 'r--', label='Validation Accuracy', linewidth=2, alpha=0.7)
            ax2.set_ylabel('Accuracy', color='black')
            ax2.legend(loc='upper right')
            ax2.set_ylim(0, 1)

            # æ ‡è®°æœ€ä½³epoch
            best_epoch = np.argmax(history['val_acc'])
            best_val_acc = history['val_acc'][best_epoch]
            ax2.axvline(x=best_epoch, color='green', linestyle=':', alpha=0.7, label=f'Best Epoch: {best_epoch}')
            ax2.legend(loc='upper right')
        else:
            ax.text(0.5, 0.5, 'No Training History Available', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Deep Learning Training History', fontsize=12, fontweight='bold')

        plt.tight_layout()
        plt.savefig(result_folder_path + 'detailed_training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_model_comparison(self, training_system, true_labels, ensemble_predictions):
        """ç»˜åˆ¶æ¨¡åž‹æ€§èƒ½å¯¹æ¯”"""
        fig = plt.figure(figsize=(10, 6))
        ax = fig.add_subplot(111)

        model_names = []
        accuracies = []
        f1_scores = []

        for model_name, predictions in training_system.predictions.items():
            accuracy = accuracy_score(true_labels, predictions)
            f1 = f1_score(true_labels, predictions, average='weighted')

            model_names.append(model_name)
            accuracies.append(accuracy)
            f1_scores.append(f1)

        # æ·»åŠ é›†æˆæ¨¡åž‹
        ensemble_accuracy = accuracy_score(true_labels, ensemble_predictions)
        ensemble_f1 = f1_score(true_labels, ensemble_predictions, average='weighted')

        model_names.append('Ensemble')
        accuracies.append(ensemble_accuracy)
        f1_scores.append(ensemble_f1)

        x = np.arange(len(model_names))
        width = 0.35

        bars1 = ax.bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue', edgecolor='black')
        bars2 = ax.bar(x + width/2, f1_scores, width, label='F1-Score', alpha=0.8, color='lightcoral', edgecolor='black')

        ax.set_xlabel('Models')
        ax.set_ylabel('Scores')
        ax.set_title('Model Performance Comparison\n(Accuracy vs F1-Score)', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(model_names, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)

        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2, height + 0.01,
                       f'{height:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')

        plt.tight_layout()
        plt.savefig(result_folder_path + 'model_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_confusion_matrix(self, predictions, true_labels, title):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾"""
        fig = plt.figure(figsize=(8, 6))
        ax = fig.add_subplot(111)

        cm = confusion_matrix(true_labels, predictions)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                   xticklabels=self.class_names,
                   yticklabels=self.class_names,
                   cbar_kws={'label': 'Count'})
        ax.set_xlabel('Predicted Labels', fontweight='bold')
        ax.set_ylabel('True Labels', fontweight='bold')
        ax.set_title(f'Confusion Matrix\n{title}', fontsize=12, fontweight='bold')

        plt.tight_layout()
        plt.savefig(result_folder_path + f'confusion_matrix_{title.lower().replace(" ", "_")}.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_cv_heatmap(self, training_system):
        """ç»˜åˆ¶äº¤å‰éªŒè¯åˆ†æ•°çƒ­åŠ›å›¾"""
        fig = plt.figure(figsize=(8, 6))
        ax = fig.add_subplot(111)

        cv_data = []
        model_names = []

        for model_name, scores in training_system.model_performances.items():
            if scores:  # åªåŒ…å«æœ‰CVåˆ†æ•°çš„æ¨¡åž‹
                cv_data.append(scores)
                model_names.append(model_name)

        if cv_data:
            cv_array = np.array(cv_data)
            sns.heatmap(cv_array, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax,
                       xticklabels=[f'Fold {i+1}' for i in range(cv_array.shape[1])],
                       yticklabels=model_names,
                       cbar_kws={'label': 'Accuracy'})
            ax.set_xlabel('Cross-Validation Folds', fontweight='bold')
            ax.set_ylabel('Models', fontweight='bold')
            ax.set_title('Cross-Validation Scores\n(5-Fold CV)', fontsize=12, fontweight='bold')
        else:
            ax.text(0.5, 0.5, 'No CV Scores Available', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Cross-Validation Scores', fontsize=12, fontweight='bold')

        plt.tight_layout()
        plt.savefig(result_folder_path + 'cv_heatmap.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_learning_rate_gradient(self, training_system):
        """ç»˜åˆ¶å­¦ä¹ çŽ‡å’Œæ¢¯åº¦å˜åŒ–"""
        fig = plt.figure(figsize=(8, 6))
        ax = fig.add_subplot(111)

        if 'Deep Learning' in training_system.epoch_details:
            details = training_system.epoch_details['Deep Learning']
            epochs = details['epochs']

            # å­¦ä¹ çŽ‡æ›²çº¿
            ax.plot(epochs, details['learning_rate'], 'g-', label='Learning Rate', linewidth=2)
            ax.set_xlabel('Epochs')
            ax.set_ylabel('Learning Rate', color='green')
            ax.tick_params(axis='y', labelcolor='green')
            ax.set_title('Learning Rate and Gradient Norm', fontsize=12, fontweight='bold')
            ax.grid(True, alpha=0.3)

            # æ¢¯åº¦èŒƒæ•°æ›²çº¿ï¼ˆåŒYè½´ï¼‰
            ax2 = ax.twinx()
            ax2.plot(epochs, details['grad_norm'], 'purple', label='Gradient Norm', linewidth=2, alpha=0.7)
            ax2.set_ylabel('Gradient Norm', color='purple')
            ax2.tick_params(axis='y', labelcolor='purple')

            # ç»„åˆå›¾ä¾‹
            lines1, labels1 = ax.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
        else:
            ax.text(0.5, 0.5, 'No Training Details Available', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Learning Rate and Gradient', fontsize=12, fontweight='bold')

        plt.tight_layout()
        plt.savefig(result_folder_path + 'learning_rate_gradient.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_predictions_correlation(self, training_system, true_labels):
        """ç»˜åˆ¶æ¨¡åž‹é¢„æµ‹ç›¸å…³æ€§çƒ­åŠ›å›¾"""
        fig = plt.figure(figsize=(8, 6))
        ax = fig.add_subplot(111)

        model_names = list(training_system.predictions.keys())
        n_models = len(model_names)

        if n_models > 1:
            corr_matrix = np.ones((n_models, n_models))

            for i in range(n_models):
                for j in range(n_models):
                    if i != j:
                        corr = np.corrcoef(training_system.predictions[model_names[i]], 
                                         training_system.predictions[model_names[j]])[0, 1]
                        corr_matrix[i, j] = corr

            sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', 
                       center=0, ax=ax, square=True,
                       xticklabels=model_names, yticklabels=model_names,
                       cbar_kws={'label': 'Correlation'})
            ax.set_title('Model Predictions Correlation', fontsize=12, fontweight='bold')
        else:
            ax.text(0.5, 0.5, 'Need Multiple Models\nfor Correlation Analysis', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Model Predictions Correlation', fontsize=12, fontweight='bold')

        plt.tight_layout()
        plt.savefig(result_folder_path + 'predictions_correlation.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_detailed_metrics(self, training_system, true_labels, ensemble_predictions):
        """ç»˜åˆ¶è¯¦ç»†æ€§èƒ½æŒ‡æ ‡"""
        fig = plt.figure(figsize=(12, 6))
        ax = fig.add_subplot(111)

        metrics_data = []
        model_names = list(training_system.predictions.keys()) + ['Ensemble']

        for model_name in model_names:
            if model_name == 'Ensemble':
                predictions = ensemble_predictions
            else:
                predictions = training_system.predictions[model_name]

            accuracy = accuracy_score(true_labels, predictions)
            precision = precision_score(true_labels, predictions, average='weighted')
            recall = recall_score(true_labels, predictions, average='weighted')
            f1 = f1_score(true_labels, predictions, average='weighted')

            metrics_data.append([accuracy, precision, recall, f1])

        metrics_array = np.array(metrics_data)
        metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

        x = np.arange(len(model_names))
        width = 0.2

        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']

        for i, metric in enumerate(metrics_names):
            bars = ax.bar(x + i*width, metrics_array[:, i], width, label=metric, color=colors[i], alpha=0.8, edgecolor='black')

            # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
            for bar, value in zip(bars, metrics_array[:, i]):
                ax.text(bar.get_x() + bar.get_width()/2, value + 0.01, f'{value:.3f}', 
                       ha='center', va='bottom', fontsize=8, rotation=45)

        ax.set_xlabel('Models', fontweight='bold')
        ax.set_ylabel('Scores', fontweight='bold')
        ax.set_title('Detailed Performance Metrics by Model', fontsize=14, fontweight='bold')
        ax.set_xticks(x + width*1.5)
        ax.set_xticklabels(model_names, rotation=45, ha='right')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)

        plt.tight_layout()
        plt.savefig(result_folder_path + 'detailed_metrics.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_training_dynamics(self, training_system):
        """ç»˜åˆ¶è®­ç»ƒåŠ¨æ€åˆ†æž"""
        fig = plt.figure(figsize=(8, 6))
        ax = fig.add_subplot(111)

        if 'Deep Learning' in training_system.epoch_details:
            details = training_system.epoch_details['Deep Learning']
            epochs = details['epochs']

            # è®¡ç®—è®­ç»ƒå’ŒéªŒè¯å·®è·
            gap = np.array(details['train_acc']) - np.array(details['val_acc'])

            ax.plot(epochs, gap, 'orange', linewidth=2, label='Train-Val Gap')
            ax.axhline(y=0, color='red', linestyle='--', alpha=0.7, label='Zero Gap')
            ax.fill_between(epochs, gap, alpha=0.3, color='orange')

            ax.set_xlabel('Epochs')
            ax.set_ylabel('Accuracy Gap')
            ax.set_title('Training Dynamics\n(Train-Validation Gap)', fontsize=12, fontweight='bold')
            ax.legend()
            ax.grid(True, alpha=0.3)

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            avg_gap = np.mean(gap)
            max_gap = np.max(gap)
            ax.text(0.02, 0.98, f'Avg Gap: {avg_gap:.3f}\nMax Gap: {max_gap:.3f}', 
                   transform=ax.transAxes, va='top', ha='left', 
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        else:
            ax.text(0.5, 0.5, 'No Training Dynamics Data', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Training Dynamics', fontsize=12, fontweight='bold')

        plt.tight_layout()
        plt.savefig(result_folder_path + 'training_dynamics.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_class_performance(self, predictions, true_labels):
        """ç»˜åˆ¶ç±»åˆ«æ€§èƒ½åˆ†æž"""
        fig = plt.figure(figsize=(10, 6))
        ax = fig.add_subplot(111)

        class_performance = []
        precision_scores = []
        recall_scores = []

        for class_idx, class_name in enumerate(self.class_names):
            class_mask = (true_labels == class_idx)
            if np.sum(class_mask) > 0:  # ç¡®ä¿æœ‰æ ·æœ¬
                class_accuracy = accuracy_score(true_labels[class_mask], predictions[class_mask])
                class_precision = precision_score(true_labels, predictions, average=None, labels=[class_idx])[0]
                class_recall = recall_score(true_labels, predictions, average=None, labels=[class_idx])[0]

                class_performance.append(class_accuracy)
                precision_scores.append(class_precision)
                recall_scores.append(class_recall)

        x = np.arange(len(self.class_names))
        width = 0.25

        ax.bar(x - width, class_performance, width, label='Accuracy', alpha=0.8, color='lightblue')
        ax.bar(x, precision_scores, width, label='Precision', alpha=0.8, color='lightcoral')
        ax.bar(x + width, recall_scores, width, label='Recall', alpha=0.8, color='lightgreen')

        ax.set_xlabel('Classes')
        ax.set_ylabel('Scores')
        ax.set_title('Class-wise Performance Analysis\n(Ensemble Model)', fontsize=12, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(self.class_names)
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (acc, prec, rec) in enumerate(zip(class_performance, precision_scores, recall_scores)):
            ax.text(i - width, acc + 0.02, f'{acc:.2f}', ha='center', va='bottom', fontsize=8)
            ax.text(i, prec + 0.02, f'{prec:.2f}', ha='center', va='bottom', fontsize=8)
            ax.text(i + width, rec + 0.02, f'{rec:.2f}', ha='center', va='bottom', fontsize=8)

        plt.tight_layout()
        plt.savefig(result_folder_path + 'class_performance.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_individual_model_confusions(self, training_system, true_labels):
        """ç»˜åˆ¶ä¸ªä½“æ¨¡åž‹æ··æ·†çŸ©é˜µ"""
        n_models = len(training_system.predictions)
        if n_models > 0:
            for idx, (model_name, predictions) in enumerate(training_system.predictions.items()):
                fig = plt.figure(figsize=(8, 6))
                ax = fig.add_subplot(111)

                cm = confusion_matrix(true_labels, predictions)
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                           xticklabels=self.class_names,
                           yticklabels=self.class_names)
                accuracy = accuracy_score(true_labels, predictions)
                ax.set_title(f'{model_name}\nAccuracy: {accuracy:.3f}', fontweight='bold')
                ax.set_xlabel('Predicted')
                ax.set_ylabel('True')

                plt.tight_layout()
                plt.savefig(result_folder_path + f'confusion_matrix_{model_name.lower().replace(" ", "_")}.png', dpi=300, bbox_inches='tight')
                plt.show()

    def _plot_training_progression(self, training_system):
        """ç»˜åˆ¶è®­ç»ƒè¿›åº¦å¯è§†åŒ–"""
        if 'Deep Learning' in training_system.epoch_details:
            details = training_system.epoch_details['Deep Learning']
            epochs = details['epochs']

            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

            # è®­ç»ƒè¿›åº¦ - æŸå¤±
            ax1.plot(epochs, details['train_loss'], 'b-', label='Training Loss', linewidth=2)
            ax1.plot(epochs, details['val_loss'], 'r-', label='Validation Loss', linewidth=2)
            ax1.set_xlabel('Epochs')
            ax1.set_ylabel('Loss')
            ax1.set_title('Training Progression - Loss', fontweight='bold')
            ax1.legend()
            ax1.grid(True, alpha=0.3)

            # è®­ç»ƒè¿›åº¦ - å‡†ç¡®çŽ‡
            ax2.plot(epochs, details['train_acc'], 'b-', label='Training Accuracy', linewidth=2)
            ax2.plot(epochs, details['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)
            ax2.set_xlabel('Epochs')
            ax2.set_ylabel('Accuracy')
            ax2.set_title('Training Progression - Accuracy', fontweight='bold')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            ax2.set_ylim(0, 1)

            plt.tight_layout()
            plt.savefig(result_folder_path + 'training_progression.png', dpi=300, bbox_inches='tight')
            plt.show()

# ========================== ä¸»å‡½æ•° ==========================
def main():
    print("Alzheimer's Disease Multimodal Recognition System - Complete Visualization")
    print("=" * 70)

    try:
        # 1. çœŸå®žæ•°æ®å¤„ç†
        processor = RealDataProcessor()
        merged_data = processor.process_all_data()

        # 2. ç‰¹å¾å·¥ç¨‹
        feature_engineer = EnhancedFeatureEngineering()
        audio_features, text_features, labels = feature_engineer.prepare_features(merged_data)

        print(f"\n=== Data Summary ===")
        print(f"Training samples: {len(labels)}")
        print(f"Audio features: {audio_features.shape}")
        print(f"Text features: {text_features.shape}")
        label_distribution = dict(zip(feature_engineer.label_encoder.classes_, np.bincount(labels)))
        print(f"Label distribution: {label_distribution}")

        # 3. è®­ç»ƒå¢žå¼ºç³»ç»Ÿ
        training_system = EnhancedTrainingSystem()
        ensemble_predictions = training_system.train_enhanced_system(
            audio_features, text_features, labels, feature_engineer
        )

        # 4. æœ€ç»ˆè¯„ä¼°
        print("\n=== Final Performance Evaluation ===")
        accuracy = accuracy_score(labels, ensemble_predictions)
        f1 = f1_score(labels, ensemble_predictions, average='weighted')

        print(f"Ensemble System Accuracy: {accuracy:.4f}")
        print(f"Ensemble System F1 Score: {f1:.4f}")
        print("\nDetailed Classification Report:")
        print(classification_report(labels, ensemble_predictions, 
                                  target_names=feature_engineer.label_encoder.classes_))

        # 5. æ€§èƒ½è¯„ä¼°
        if accuracy >= 0.85:
            print("ðŸŽ‰ Outstanding! System achieved top performance!")
        elif accuracy >= 0.75:
            print("âœ… Excellent! Robust performance achieved!")
        elif accuracy >= 0.65:
            print("âš ï¸ Good performance, consider further optimization")
        else:
            print("âŒ Needs improvement")

        # 6. ç»¼åˆå¯è§†åŒ–
        visualizer = EnhancedVisualization(feature_engineer)
        visualizer.plot_comprehensive_training_analysis(training_system, ensemble_predictions, labels)

        # 7. ä¿å­˜æ¨¡åž‹
        torch.save({
            'training_system': training_system,
            'feature_engineer': feature_engineer,
            'accuracy': accuracy,
            'model_state_dict': training_system.models['Deep Learning'].state_dict() if 'Deep Learning' in training_system.models else None
        }, 'complete_alzheimer_system.pth')

        print(f"\nModel saved: complete_alzheimer_system.pth")

        print("\n" + "="*50)
        print("System training and visualization completed!")
        print("Ready for deployment.")
        print("="*50)

    except Exception as e:
        print(f"Runtime error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()


# In[4]:


# -*- coding: utf-8 -*-
"""
é˜¿å°”èŒ¨æµ·é»˜ç—‡å¤šæ¨¡æ€è¯†åˆ«ç³»ç»Ÿ - å®Œæ•´ä¼˜åŒ–ç‰ˆ
é›†æˆè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ï¼Œä¸­æ–‡æ³¨é‡Šï¼Œè‹±æ–‡æ ‡ç­¾æ˜¾ç¤ºï¼Œå¤šæ¨¡æ€èžåˆ
"""

import os
import pandas as pd
import numpy as np
import time
from tqdm import tqdm
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import (roc_auc_score, recall_score, f1_score, 
                           accuracy_score, classification_report, 
                           confusion_matrix, precision_score, roc_curve, auc)
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.decomposition import PCA
import lightgbm as lgb
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from torch.optim.lr_scheduler import ReduceLROnPlateau
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®
plt.rcParams['font.size'] = 12
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# ========================== é«˜çº§æ•°æ®å¤„ç†å™¨ ==========================
class AdvancedDataProcessor:
    """é«˜çº§æ•°æ®å¤„ç†å™¨ - æ”¯æŒå¤šç§æ•°æ®æºå’Œå¢žå¼ºç‰¹å¾å·¥ç¨‹"""

    def __init__(self, base_path='./kaggle/input/alzheimer/data/'):
        self.base_path = base_path
        self.egemaps_pre_path = os.path.join(base_path, 'egemaps_final.csv')
        self.train_list_path = os.path.join(base_path, '2_final_list_train.csv')
        self.test_list_path = os.path.join(base_path, '2_final_list_test.csv')
        self.tsv_dir = os.path.join(base_path, 'tsv2/')
        self.egemaps_dir = '/data/egemaps2/'

    def process_all_data(self):
        """å¤„ç†æ‰€æœ‰æ•°æ®å¹¶è¿›è¡Œé«˜çº§ç‰¹å¾å·¥ç¨‹"""
        print("=== Processing Alzheimer's Disease Data with Advanced Features ===")

        # 1. åŠ è½½åŸºç¡€æ•°æ®
        print("1. Loading basic data...")
        preliminary_list_test = pd.read_csv(self.test_list_path)
        preliminary_list_train = pd.read_csv(self.train_list_path)
        egemaps_pre = pd.read_csv(self.egemaps_pre_path)

        print(f"Training set: {preliminary_list_train.shape}")
        print(f"Test set: {preliminary_list_test.shape}")
        print(f"Precomputed features: {egemaps_pre.shape}")
        print('Training set label distribution:\n', preliminary_list_train['label'].value_counts())

        # 2. ä»ŽTSVæ–‡ä»¶æå–å¢žå¼ºæ–‡æœ¬ç‰¹å¾
        print("\n2. Extracting enhanced text features from TSV files...")
        text_features = self._extract_enhanced_text_features()

        # 3. ä»ŽeGeMAPSæ–‡ä»¶æå–å¢žå¼ºéŸ³é¢‘ç‰¹å¾
        print("\n3. Extracting enhanced audio features from eGeMAPS files...")
        audio_features = self._extract_enhanced_audio_features()

        # 4. åˆå¹¶æ‰€æœ‰ç‰¹å¾å¹¶è¿›è¡Œé«˜çº§å¤„ç†
        print("\n4. Merging all features with advanced processing...")
        merged_data = self._merge_all_features_advanced(
            preliminary_list_train, preliminary_list_test, 
            egemaps_pre, text_features, audio_features
        )

        return merged_data

    def _extract_enhanced_text_features(self):
        """æå–å¢žå¼ºæ–‡æœ¬ç‰¹å¾"""
        tsv_path_lists = os.listdir(self.tsv_dir)
        tsv_feats = []

        print(f"Processing {len(tsv_path_lists)} TSV files with enhanced features...")

        for path in tqdm(tsv_path_lists):
            try:
                z = pd.read_csv(os.path.join(self.tsv_dir, path), sep='\t')
                z['duration'] = z['end_time'] - z['start_time']

                # åŸºç¡€ç»Ÿè®¡ç‰¹å¾
                duration_stats = [
                    z['duration'].mean(), z['duration'].min(), z['duration'].max(),
                    z['duration'].std(), z['duration'].median(), z['duration'].skew(),
                    z['duration'].kurtosis(), z.shape[0]
                ]

                # é«˜çº§ç»Ÿè®¡ç‰¹å¾
                advanced_stats = [
                    z['duration'].quantile(0.25), z['duration'].quantile(0.75),
                    z['duration'].quantile(0.90), (z['duration'] > 5).sum(),
                    (z['duration'] < 1).sum(), len(z[z['duration'] > z['duration'].mean()])
                ]

                # è¯´è¯æ¨¡å¼ç‰¹å¾
                speaking_pattern = [
                    z['duration'].sum(),  # æ€»æ—¶é•¿
                    len(z) / max(z['duration'].sum(), 1),  # è¯­é€Ÿï¼ˆå¥å­æ•°/æ€»æ—¶é•¿ï¼‰
                    (z['duration'] > 2).mean(),  # é•¿åœé¡¿æ¯”ä¾‹
                    (z['duration'] < 0.5).mean()  # çŸ­åœé¡¿æ¯”ä¾‹
                ]

                feature_vector = [path[:-4]] + duration_stats + advanced_stats + speaking_pattern
                tsv_feats.append(feature_vector)

            except Exception as e:
                print(f"Error processing file {path}: {e}")
                continue

        # åˆ›å»ºDataFrame
        tsv_feats_df = pd.DataFrame(tsv_feats)
        base_columns = ['uuid', 'text_mean_dur', 'text_min_dur', 'text_max_dur', 
                       'text_std_dur', 'text_median_dur', 'text_skew_dur', 
                       'text_kurt_dur', 'text_num_sentences']
        advanced_columns = ['text_q25_dur', 'text_q75_dur', 'text_q90_dur',
                          'text_long_sentences', 'text_short_sentences', 
                          'text_above_avg_sentences']
        pattern_columns = ['text_total_dur', 'text_speech_rate', 
                          'text_long_pause_ratio', 'text_short_pause_ratio']

        tsv_feats_df.columns = base_columns + advanced_columns + pattern_columns

        print(f"Enhanced text features extracted: {tsv_feats_df.shape}")
        return tsv_feats_df

    def _extract_enhanced_audio_features(self):
        """æå–å¢žå¼ºéŸ³é¢‘ç‰¹å¾"""
        try:
            egemaps_path_lists = os.listdir(self.egemaps_dir)
        except:
            print(f"eGeMAPS directory not found: {self.egemaps_dir}")
            return None

        egemaps_feats = []

        print(f"Processing {len(egemaps_path_lists)} eGeMAPS files with enhanced features...")

        for path in tqdm(egemaps_path_lists):
            try:
                z = pd.read_csv(os.path.join(self.egemaps_dir, path), sep=';')
                if 'name' in z.columns:
                    z = z.drop(['name'], axis=1)

                feature_vector = [path[:-4]]  # uuid

                # åŸºç¡€ç»Ÿè®¡ç‰¹å¾
                feature_vector.extend(list(z.mean(axis=0)))    # å‡å€¼
                feature_vector.extend(list(z.std(axis=0)))     # æ ‡å‡†å·®
                feature_vector.extend(list(z.min(axis=0)))     # æœ€å°å€¼
                feature_vector.extend(list(z.median(axis=0)))  # ä¸­ä½æ•°
                feature_vector.extend(list(z.max(axis=0)))     # æœ€å¤§å€¼

                # é«˜çº§ç»Ÿè®¡ç‰¹å¾
                feature_vector.extend(list(z.quantile(0.25)))  # 25%åˆ†ä½æ•°
                feature_vector.extend(list(z.quantile(0.75)))  # 75%åˆ†ä½æ•°
                feature_vector.extend(list(z.skew(axis=0)))    # ååº¦
                feature_vector.extend(list(z.kurtosis(axis=0))) # å³°åº¦

                egemaps_feats.append(feature_vector)

            except Exception as e:
                print(f"Error processing audio file {path}: {e}")
                continue

        if egemaps_feats:
            egemaps_feats_df = pd.DataFrame(egemaps_feats)
            n_features = z.shape[1]  # åŽŸå§‹ç‰¹å¾æ•°é‡

            columns = ['uuid']
            # åˆ›å»ºæè¿°æ€§åˆ—å
            stats = ['mean', 'std', 'min', 'median', 'max', 'q25', 'q75', 'skew', 'kurt']
            for stat in stats:
                for i in range(n_features):
                    columns.append(f'audio_{stat}_{i:03d}')

            egemaps_feats_df.columns = columns[:egemaps_feats_df.shape[1]]
            print(f"Enhanced audio features extracted: {egemaps_feats_df.shape}")
            return egemaps_feats_df
        else:
            return None

    def _merge_all_features_advanced(self, train_list, test_list, egemaps_pre, text_features, audio_features):
        """é«˜çº§ç‰¹å¾åˆå¹¶å’Œå¤„ç†"""
        print("Merging features with advanced processing...")

        # åˆå¹¶è®­ç»ƒå’Œæµ‹è¯•é›†
        all_data = pd.concat([train_list, test_list], ignore_index=True)
        print(f"Combined data: {all_data.shape}")

        # ç¡®ä¿uuidåˆ—ç±»åž‹ä¸€è‡´
        all_data['uuid'] = all_data['uuid'].astype(str)
        egemaps_pre['uuid'] = egemaps_pre['uuid'].astype(str)
        text_features['uuid'] = text_features['uuid'].astype(str)

        # é€æ­¥åˆå¹¶ç‰¹å¾
        merged_data = pd.merge(all_data, egemaps_pre, on='uuid', how='left')
        print(f"After eGeMAPS merge: {merged_data.shape}")

        merged_data = pd.merge(merged_data, text_features, on='uuid', how='left')
        print(f"After text features merge: {merged_data.shape}")

        if audio_features is not None:
            audio_features['uuid'] = audio_features['uuid'].astype(str)
            merged_data = pd.merge(merged_data, audio_features, on='uuid', how='left')
            print(f"After audio features merge: {merged_data.shape}")

        # é«˜çº§æ•°æ®æ¸…æ´—å’Œå¤„ç†
        merged_data = self._advanced_data_cleaning(merged_data)

        print(f"Final merged data shape: {merged_data.shape}")
        print("Label distribution in final data:")
        print(merged_data['label'].value_counts())

        return merged_data

    def _advanced_data_cleaning(self, data):
        """é«˜çº§æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†"""
        # ç§»é™¤ç¼ºå¤±æ ‡ç­¾çš„è¡Œ
        data = data[data['label'].notna()]
        data = data[data['label'] != '']
        data = data[data['label'] != 'nan']

        # æ ‡å‡†åŒ–æ ‡ç­¾
        data['label'] = data['label'].astype(str).str.upper().str.strip()

        # è¯†åˆ«ç‰¹å¾åˆ—
        feature_columns = [col for col in data.columns if col not in ['uuid', 'label', 'sex', 'age', 'education']]

        # å¤„ç†ç¼ºå¤±å€¼
        for col in feature_columns:
            if data[col].isna().sum() > 0:
                if data[col].dtype in ['float64', 'int64']:
                    # å¯¹äºŽæ•°å€¼åˆ—ï¼Œä½¿ç”¨ä¸­ä½æ•°å¡«å……
                    data[col].fillna(data[col].median(), inplace=True)
                else:
                    # å¯¹äºŽå…¶ä»–åˆ—ï¼Œä½¿ç”¨ä¼—æ•°å¡«å……
                    data[col].fillna(data[col].mode()[0] if len(data[col].mode()) > 0 else 'unknown', inplace=True)

        # å¤„ç†å¼‚å¸¸å€¼
        for col in feature_columns:
            if data[col].dtype in ['float64', 'int64']:
                Q1 = data[col].quantile(0.25)
                Q3 = data[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                data[col] = np.clip(data[col], lower_bound, upper_bound)

        return data

# ========================== é«˜çº§ç‰¹å¾å·¥ç¨‹ ==========================
class AdvancedFeatureEngineering:
    """é«˜çº§ç‰¹å¾å·¥ç¨‹ - åŒ…å«ç‰¹å¾é€‰æ‹©ã€é™ç»´å’Œç‰¹å¾äº¤å‰"""

    def __init__(self):
        self.scaler_audio = StandardScaler()
        self.scaler_text = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.audio_columns = None
        self.text_columns = None
        self.selected_audio_columns = None
        self.selected_text_columns = None
        self.pca_audio = None
        self.pca_text = None

    def prepare_features(self, data, use_pca=False, n_audio_components=50, n_text_components=10):
        """å‡†å¤‡ç‰¹å¾ç”¨äºŽæ¨¡åž‹è®­ç»ƒ"""
        print("\n=== Advanced Feature Engineering ===")

        # ç¼–ç æ ‡ç­¾
        labels = self.label_encoder.fit_transform(data['label'])
        label_mapping = dict(zip(self.label_encoder.classes_, range(len(self.label_encoder.classes_))))
        print(f"Label encoding: {label_mapping}")

        # è¯†åˆ«ç‰¹å¾åˆ—
        feature_columns = [col for col in data.columns if col not in ['uuid', 'label', 'sex', 'age', 'education']]

        # åˆ†ç¦»éŸ³é¢‘å’Œæ–‡æœ¬ç‰¹å¾
        self.audio_columns = [col for col in feature_columns if any(keyword in col.lower() for keyword in 
                            ['f0', 'rms', 'mfcc', 'spectral', 'energy', 'loudness', 'jitter', 'shimmer', 'hnr', 'audio'])]
        self.text_columns = [col for col in feature_columns if any(keyword in col.lower() for keyword in 
                           ['text_feat', 'duration', 'sentence', 'speech', 'pause'])]

        # å¦‚æžœè‡ªåŠ¨æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨æ‰‹åŠ¨åˆ†é…
        if not self.audio_columns:
            self.audio_columns = feature_columns[:min(88, len(feature_columns))]
        if not self.text_columns:
            self.text_columns = [col for col in feature_columns if col not in self.audio_columns]

        print(f"Audio features identified: {len(self.audio_columns)}")
        print(f"Text features identified: {len(self.text_columns)}")

        # ç‰¹å¾é€‰æ‹©
        selected_audio, selected_text = self._advanced_feature_selection(
            data[self.audio_columns], data[self.text_columns], labels
        )

        # å¯é€‰PCAé™ç»´
        if use_pca:
            selected_audio, selected_text = self._apply_pca(
                selected_audio, selected_text, n_audio_components, n_text_components
            )

        # ç‰¹å¾äº¤å‰
        crossed_features = self._create_feature_crosses(selected_audio, selected_text)

        # æ ‡å‡†åŒ–
        audio_features = self.scaler_audio.fit_transform(selected_audio)
        text_features = self.scaler_text.fit_transform(selected_text)

        print(f"Final feature dimensions - Audio: {audio_features.shape}, Text: {text_features.shape}")
        if crossed_features is not None:
            print(f"Crossed features: {crossed_features.shape}")

        return audio_features, text_features, crossed_features, labels

    def _advanced_feature_selection(self, audio_data, text_data, labels):
        """é«˜çº§ç‰¹å¾é€‰æ‹©æ–¹æ³•"""
        print("Performing advanced feature selection...")

        # éŸ³é¢‘ç‰¹å¾é€‰æ‹© - ä½¿ç”¨å¤šç§æ–¹æ³•
        if audio_data.shape[1] > 50:
            # æ–¹æ³•1: åŸºäºŽæ–¹å·®é€‰æ‹©
            variances = audio_data.var(axis=0)
            high_var_indices = np.where(variances > np.percentile(variances, 25))[0]
            audio_data = audio_data.iloc[:, high_var_indices]

            # æ–¹æ³•2: åŸºäºŽç›¸å…³æ€§é€‰æ‹©
            if audio_data.shape[1] > 50:
                corr_matrix = audio_data.corr().abs()
                upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
                to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]
                audio_data = audio_data.drop(to_drop, axis=1)

            # æ–¹æ³•3: åŸºäºŽç»Ÿè®¡æ£€éªŒé€‰æ‹©
            if audio_data.shape[1] > 50:
                selector = SelectKBest(f_classif, k=min(50, audio_data.shape[1]))
                audio_selected = selector.fit_transform(audio_data, labels)
                self.selected_audio_columns = [self.audio_columns[i] for i in selector.get_support(indices=True)]
            else:
                audio_selected = audio_data.values
                self.selected_audio_columns = audio_data.columns.tolist()
        else:
            audio_selected = audio_data.values
            self.selected_audio_columns = self.audio_columns

        # æ–‡æœ¬ç‰¹å¾é€‰æ‹©
        if text_data.shape[1] > 15:
            selector_text = SelectKBest(f_classif, k=min(15, text_data.shape[1]))
            text_selected = selector_text.fit_transform(text_data, labels)
            self.selected_text_columns = [self.text_columns[i] for i in selector_text.get_support(indices=True)]
        else:
            text_selected = text_data.values
            self.selected_text_columns = self.text_columns

        print(f"Selected {len(self.selected_audio_columns)} audio features")
        print(f"Selected {len(self.selected_text_columns)} text features")

        return audio_selected, text_selected

    def _apply_pca(self, audio_features, text_features, n_audio_components, n_text_components):
        """åº”ç”¨PCAé™ç»´"""
        print("Applying PCA for dimensionality reduction...")

        # éŸ³é¢‘ç‰¹å¾PCA
        n_audio_components = min(n_audio_components, audio_features.shape[1])
        self.pca_audio = PCA(n_components=n_audio_components, random_state=SEED)
        audio_pca = self.pca_audio.fit_transform(audio_features)

        # æ–‡æœ¬ç‰¹å¾PCA
        n_text_components = min(n_text_components, text_features.shape[1])
        self.pca_text = PCA(n_components=n_text_components, random_state=SEED)
        text_pca = self.pca_text.fit_transform(text_features)

        print(f"PCA explained variance - Audio: {self.pca_audio.explained_variance_ratio_.sum():.3f}, "
              f"Text: {self.pca_text.explained_variance_ratio_.sum():.3f}")

        return audio_pca, text_pca

    def _create_feature_crosses(self, audio_features, text_features):
        """åˆ›å»ºç‰¹å¾äº¤å‰"""
        if audio_features.shape[1] == 0 or text_features.shape[1] == 0:
            return None

        # é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾è¿›è¡Œäº¤å‰
        n_crosses = min(5, min(audio_features.shape[1], text_features.shape[1]))

        crossed_features = []
        for i in range(n_crosses):
            for j in range(n_crosses):
                if i < audio_features.shape[1] and j < text_features.shape[1]:
                    cross_feature = audio_features[:, i] * text_features[:, j]
                    crossed_features.append(cross_feature)

        if crossed_features:
            crossed_features = np.column_stack(crossed_features)
            print(f"Created {crossed_features.shape[1]} cross features")
            return crossed_features
        return None

# ========================== é«˜çº§å¤šæ¨¡æ€ç¥žç»ç½‘ç»œ ==========================
class AdvancedMultiModalNet(nn.Module):
    """é«˜çº§å¤šæ¨¡æ€ç¥žç»ç½‘ç»œ - æ”¯æŒæ³¨æ„åŠ›æœºåˆ¶å’Œæ·±åº¦ç‰¹å¾èžåˆ"""

    def __init__(self, audio_dim, text_dim, num_classes=3, use_attention=True, dropout_rate=0.3):
        super(AdvancedMultiModalNet, self).__init__()

        self.use_attention = use_attention
        self.audio_dim = audio_dim
        self.text_dim = text_dim

        # éŸ³é¢‘ç¼–ç å™¨
        self.audio_encoder = nn.Sequential(
            nn.Linear(audio_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
        )

        # æ–‡æœ¬ç¼–ç å™¨
        self.text_encoder = nn.Sequential(
            nn.Linear(text_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
        )

        # æ³¨æ„åŠ›æœºåˆ¶
        if use_attention:
            self.audio_attention = nn.Sequential(
                nn.Linear(128, 64),
                nn.Tanh(),
                nn.Linear(64, 1),
                nn.Softmax(dim=1)
            )
            self.text_attention = nn.Sequential(
                nn.Linear(64, 32),
                nn.Tanh(),
                nn.Linear(32, 1),
                nn.Softmax(dim=1)
            )

        # åˆ†ç±»å™¨
        classifier_input_dim = 128 + 64 if not use_attention else 128 + 64
        self.classifier = nn.Sequential(
            nn.Linear(classifier_input_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(dropout_rate + 0.1),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(dropout_rate - 0.1),
            nn.Linear(128, num_classes)
        )

    def forward(self, audio_features, text_features):
        audio_encoded = self.audio_encoder(audio_features)
        text_encoded = self.text_encoder(text_features)

        if self.use_attention:
            # åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶
            audio_weights = self.audio_attention(audio_encoded)
            text_weights = self.text_attention(text_encoded)

            audio_attended = audio_encoded * audio_weights
            text_attended = text_encoded * text_weights

            # æ‹¼æŽ¥ç‰¹å¾
            combined = torch.cat([audio_attended, text_attended], dim=1)
        else:
            combined = torch.cat([audio_encoded, text_encoded], dim=1)

        output = self.classifier(combined)
        return output

# ========================== é«˜çº§è®­ç»ƒç³»ç»Ÿ ==========================
class AdvancedTrainingSystem:
    """é«˜çº§è®­ç»ƒç³»ç»Ÿ - æ”¯æŒå¤šç§è®­ç»ƒç­–ç•¥å’Œè¯¦ç»†ç›‘æŽ§"""

    def __init__(self):
        self.models = {}
        self.predictions = {}
        self.training_histories = {}
        self.model_performances = {}
        self.epoch_details = {}
        self.feature_importances = {}

    def train_advanced_system(self, audio_features, text_features, crossed_features, labels, feature_engineer):
        """è®­ç»ƒé«˜çº§ç³»ç»Ÿ"""
        print("\n=== Training Advanced Multi-Modal System ===")

        # 1. é«˜çº§æ·±åº¦å­¦ä¹ æ¨¡åž‹
        print("1. Training Advanced Deep Learning Model...")
        dl_predictions, dl_model, dl_history, dl_epoch_details = self._train_advanced_deep_learning(
            audio_features, text_features, labels, feature_engineer
        )
        self.models['Advanced Deep Learning'] = dl_model
        self.predictions['Advanced Deep Learning'] = dl_predictions
        self.training_histories['Advanced Deep Learning'] = dl_history
        self.epoch_details['Advanced Deep Learning'] = dl_epoch_details

        # 2. å¤šæ¨¡æ€é›†æˆæ¨¡åž‹
        print("2. Training Multi-Modal Ensemble Models...")
        ensemble_results = self._train_multimodal_ensemble(
            audio_features, text_features, crossed_features, labels
        )
        self.models.update(ensemble_results['models'])
        self.predictions.update(ensemble_results['predictions'])
        self.model_performances.update(ensemble_results['performances'])

        # 3. é«˜çº§é›†æˆ
        print("3. Advanced Model Ensemble...")
        ensemble_predictions = self._advanced_ensemble_predictions(labels)

        return ensemble_predictions

    def _train_advanced_deep_learning(self, audio_features, text_features, labels, feature_engineer):
        """è®­ç»ƒé«˜çº§æ·±åº¦å­¦ä¹ æ¨¡åž‹"""
        # æ•°æ®åˆ†å‰²
        indices = np.arange(len(labels))
        train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=SEED, stratify=labels)

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TensorDataset(
            torch.FloatTensor(audio_features[train_idx]),
            torch.FloatTensor(text_features[train_idx]),
            torch.LongTensor(labels[train_idx])
        )
        val_dataset = TensorDataset(
            torch.FloatTensor(audio_features[val_idx]),
            torch.FloatTensor(text_features[val_idx]),
            torch.LongTensor(labels[val_idx])
        )

        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

        # åˆ›å»ºæ¨¡åž‹
        model = AdvancedMultiModalNet(
            audio_features.shape[1],
            text_features.shape[1],
            num_classes=len(feature_engineer.label_encoder.classes_),
            use_attention=True,
            dropout_rate=0.4
        ).to(device)

        # é«˜çº§è®­ç»ƒè®¾ç½®
        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, verbose=True)
        criterion = nn.CrossEntropyLoss()

        # è®­ç»ƒåŽ†å²è®°å½•
        train_losses, val_losses = [], []
        train_accuracies, val_accuracies = [], []
        learning_rates = []

        # è¯¦ç»†epochä¿¡æ¯
        epoch_details = {
            'epochs': [], 'train_loss': [], 'val_loss': [],
            'train_acc': [], 'val_acc': [], 'learning_rate': [], 'grad_norm': []
        }

        best_val_acc = 0
        patience = 30
        no_improve = 0

        print("Advanced Deep Learning Training Progress:")
        print("Epoch | Train Loss | Val Loss | Train Acc | Val Acc | LR")
        print("-" * 65)

        for epoch in range(200):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            epoch_train_loss, train_correct, train_total = 0, 0, 0
            total_grad_norm = 0

            for audio_batch, text_batch, labels_batch in train_loader:
                audio_batch, text_batch, labels_batch = (
                    audio_batch.to(device), text_batch.to(device), labels_batch.to(device)
                )

                optimizer.zero_grad()
                outputs = model(audio_batch, text_batch)
                loss = criterion(outputs, labels_batch)
                loss.backward()

                # æ¢¯åº¦è£å‰ª
                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                total_grad_norm += grad_norm.item()

                optimizer.step()

                epoch_train_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                train_total += labels_batch.size(0)
                train_correct += (predicted == labels_batch).sum().item()

            avg_grad_norm = total_grad_norm / len(train_loader)
            train_acc = train_correct / train_total

            # éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss, val_correct, val_total = 0, 0, 0

            with torch.no_grad():
                for audio_batch, text_batch, labels_batch in val_loader:
                    audio_batch, text_batch, labels_batch = (
                        audio_batch.to(device), text_batch.to(device), labels_batch.to(device)
                    )
                    outputs = model(audio_batch, text_batch)
                    loss = criterion(outputs, labels_batch)
                    val_loss += loss.item()

                    _, predicted = torch.max(outputs.data, 1)
                    val_total += labels_batch.size(0)
                    val_correct += (predicted == labels_batch).sum().item()

            val_acc = val_correct / val_total

            # å­¦ä¹ çŽ‡è°ƒåº¦
            scheduler.step(val_acc)
            current_lr = optimizer.param_groups[0]['lr']

            # è®°å½•ä¿¡æ¯
            train_losses.append(epoch_train_loss / len(train_loader))
            val_losses.append(val_loss / len(val_loader))
            train_accuracies.append(train_acc)
            val_accuracies.append(val_acc)
            learning_rates.append(current_lr)

            epoch_details['epochs'].append(epoch)
            epoch_details['train_loss'].append(epoch_train_loss / len(train_loader))
            epoch_details['val_loss'].append(val_loss / len(val_loader))
            epoch_details['train_acc'].append(train_acc)
            epoch_details['val_acc'].append(val_acc)
            epoch_details['learning_rate'].append(current_lr)
            epoch_details['grad_norm'].append(avg_grad_norm)

            # æ‰“å°è¿›åº¦
            if epoch % 20 == 0:
                print(f"{epoch:5d} | {epoch_train_loss/len(train_loader):10.4f} | {val_loss/len(val_loader):8.4f} | "
                      f"{train_acc:9.4f} | {val_acc:7.4f} | {current_lr:.6f}")

            # æ—©åœæ£€æŸ¥
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                no_improve = 0
                best_model_state = model.state_dict().copy()
                best_epoch = epoch
            else:
                no_improve += 1
                if no_improve >= patience:
                    print(f"Early stopping at epoch {epoch}, best validation accuracy: {best_val_acc:.4f} at epoch {best_epoch}")
                    break

        # åŠ è½½æœ€ä½³æ¨¡åž‹
        model.load_state_dict(best_model_state)

        # æœ€ç»ˆé¢„æµ‹
        model.eval()
        with torch.no_grad():
            audio_tensor = torch.FloatTensor(audio_features).to(device)
            text_tensor = torch.FloatTensor(text_features).to(device)
            outputs = model(audio_tensor, text_tensor)
            _, predictions = torch.max(outputs, 1)

        accuracy = accuracy_score(labels, predictions.cpu().numpy())
        print(f"  Advanced Deep Learning Final Accuracy: {accuracy:.4f}")

        history = {
            'train_loss': train_losses,
            'val_loss': val_losses,
            'train_acc': train_accuracies,
            'val_acc': val_accuracies,
            'learning_rates': learning_rates
        }

        return predictions.cpu().numpy(), model, history, epoch_details

    def _train_multimodal_ensemble(self, audio_features, text_features, crossed_features, labels):
        """è®­ç»ƒå¤šæ¨¡æ€é›†æˆæ¨¡åž‹"""
        results = {'models': {}, 'predictions': {}, 'performances': {}}

        # ç»„åˆç‰¹å¾
        if crossed_features is not None:
            combined_features = np.concatenate([audio_features, text_features, crossed_features], axis=1)
        else:
            combined_features = np.concatenate([audio_features, text_features], axis=1)

        # æ¨¡åž‹åˆ—è¡¨
        models_config = {
            'LightGBM': lgb.LGBMClassifier(
                n_estimators=1000, learning_rate=0.05, num_leaves=31,
                random_state=SEED, verbose=-1, n_jobs=-1
            ),
            'XGBoost': xgb.XGBClassifier(
                n_estimators=1000, learning_rate=0.05, max_depth=6,
                random_state=SEED, n_jobs=-1, eval_metric='logloss'
            ),
            'Random Forest': RandomForestClassifier(
                n_estimators=500, max_depth=15, min_samples_split=5,
                random_state=SEED, n_jobs=-1
            ),
            'Gradient Boosting': GradientBoostingClassifier(
                n_estimators=500, learning_rate=0.05, max_depth=6,
                random_state=SEED
            ),
            'SVM': SVC(
                C=1.0, kernel='rbf', gamma='scale', random_state=SEED, probability=True
            )
        }

        # 5æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ
        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)

        for model_name, model in models_config.items():
            print(f"  Training {model_name}...")
            predictions = np.zeros(len(labels))
            fold_scores = []

            for fold, (train_idx, val_idx) in enumerate(kf.split(combined_features, labels)):
                X_train, X_val = combined_features[train_idx], combined_features[val_idx]
                y_train, y_val = labels[train_idx], labels[val_idx]

                model.fit(X_train, y_train)
                fold_pred = model.predict(X_val)
                predictions[val_idx] = fold_pred

                fold_accuracy = accuracy_score(y_val, fold_pred)
                fold_scores.append(fold_accuracy)

            accuracy = accuracy_score(labels, predictions)
            print(f"    {model_name} Accuracy: {accuracy:.4f}")

            results['models'][model_name] = model
            results['predictions'][model_name] = predictions
            results['performances'][model_name] = fold_scores

            # ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
            if hasattr(model, 'feature_importances_'):
                self.feature_importances[model_name] = model.feature_importances_

        return results

    def _advanced_ensemble_predictions(self, true_labels):
        """é«˜çº§é›†æˆé¢„æµ‹"""
        all_predictions = list(self.predictions.values())
        all_model_names = list(self.predictions.keys())

        # åŠ æƒæŠ•ç¥¨ï¼ˆåŸºäºŽæ¨¡åž‹æ€§èƒ½ï¼‰
        model_weights = {}
        for model_name, predictions in self.predictions.items():
            accuracy = accuracy_score(true_labels, predictions)
            model_weights[model_name] = accuracy

        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(model_weights.values())
        for model_name in model_weights:
            model_weights[model_name] /= total_weight

        # åŠ æƒæŠ•ç¥¨
        final_predictions = []
        for i in range(len(true_labels)):
            weighted_votes = {}
            for model_name, predictions in self.predictions.items():
                vote = predictions[i]
                weight = model_weights[model_name]
                if vote in weighted_votes:
                    weighted_votes[vote] += weight
                else:
                    weighted_votes[vote] = weight

            # é€‰æ‹©æƒé‡æœ€é«˜çš„ç±»åˆ«
            final_pred = max(weighted_votes.items(), key=lambda x: x[1])[0]
            final_predictions.append(final_pred)

        accuracy = accuracy_score(true_labels, final_predictions)
        print(f"  Advanced Ensemble Accuracy: {accuracy:.4f}")

        return np.array(final_predictions)

# ========================== é«˜çº§å¯è§†åŒ–ç³»ç»Ÿ ==========================
class AdvancedVisualization:
    """é«˜çº§å¯è§†åŒ–ç³»ç»Ÿ - æ”¯æŒå¤šç§åˆ†æžå›¾è¡¨å’Œäº¤äº’å¼å¯è§†åŒ–"""

    def __init__(self, feature_engineer):
        self.feature_engineer = feature_engineer
        self.class_names = feature_engineer.label_encoder.classes_

    def plot_comprehensive_analysis(self, training_system, ensemble_predictions, true_labels, feature_engineer):
        """ç»˜åˆ¶å…¨é¢çš„åˆ†æžå›¾è¡¨"""
        print("\n=== Generating Comprehensive Analysis ===")

        # åˆ›å»ºå›¾è¡¨ç›®å½•
        os.makedirs('analysis_plots', exist_ok=True)

        # 1. æ•°æ®åˆ†å¸ƒåˆ†æž
        self._plot_data_distribution_analysis(true_labels, feature_engineer)

        # 2. é«˜çº§è®­ç»ƒåŽ†å²
        self._plot_advanced_training_history(training_system)

        # 3. æ¨¡åž‹æ€§èƒ½é›·è¾¾å›¾
        self._plot_model_performance_radar(training_system, true_labels, ensemble_predictions)

        # 4. å¤šæ¨¡åž‹æ··æ·†çŸ©é˜µç½‘æ ¼
        self._plot_multimodel_confusion_grid(training_system, true_labels, ensemble_predictions)

        # 5. ç‰¹å¾é‡è¦æ€§åˆ†æž
        self._plot_feature_importance_analysis(training_system, feature_engineer)

        # 6. ROCæ›²çº¿åˆ†æž
        self._plot_roc_analysis(training_system, true_labels)

        # 7. è®­ç»ƒåŠ¨æ€çƒ­åŠ›å›¾
        self._plot_training_dynamics_heatmap(training_system)

        # 8. æ¨¡åž‹ç›¸å…³æ€§çŸ©é˜µ
        self._plot_model_correlation_matrix(training_system, true_labels)

        # 9. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
        self._plot_performance_comparison(training_system, true_labels, ensemble_predictions)

        # 10. ç±»åˆ«æ€§èƒ½åˆ†æž
        self._plot_class_performance_analysis(ensemble_predictions, true_labels)

        print("All analysis plots saved to 'analysis_plots' directory")

    def _plot_data_distribution_analysis(self, true_labels, feature_engineer):
        """ç»˜åˆ¶æ•°æ®åˆ†å¸ƒåˆ†æž"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

        # 1. æ ‡ç­¾åˆ†å¸ƒ
        label_counts = np.bincount(true_labels)
        ax1.bar(range(len(label_counts)), label_counts, color=['skyblue', 'lightcoral', 'lightgreen'])
        ax1.set_xlabel('Classes')
        ax1.set_ylabel('Count')
        ax1.set_title('Class Distribution', fontweight='bold')
        ax1.set_xticks(range(len(self.class_names)))
        ax1.set_xticklabels(self.class_names)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, count in enumerate(label_counts):
            ax1.text(i, count + 0.1, str(count), ha='center', va='bottom', fontweight='bold')

        # 2. æ ‡ç­¾åˆ†å¸ƒé¥¼å›¾
        colors = ['#ff9999', '#66b3ff', '#99ff99']
        ax2.pie(label_counts, labels=self.class_names, autopct='%1.1f%%', 
                colors=colors, startangle=90)
        ax2.set_title('Class Distribution (Percentage)', fontweight='bold')

        # 3. è®­ç»ƒé›†å¤§å°åˆ†æž
        ax3.barh(['Total Samples'], [len(true_labels)], color='lightblue')
        ax3.set_xlabel('Number of Samples')
        ax3.set_title('Dataset Size', fontweight='bold')
        ax3.text(len(true_labels)/2, 0, f'{len(true_labels)} samples', 
                ha='center', va='center', fontweight='bold', fontsize=12)

        # 4. ç±»åˆ«å¹³è¡¡åˆ†æž
        balance_ratio = min(label_counts) / max(label_counts) if max(label_counts) > 0 else 0
        ax4.bar(['Balance Ratio'], [balance_ratio], color='orange')
        ax4.set_ylabel('Ratio (Min/Max)')
        ax4.set_title(f'Class Balance Analysis\nRatio: {balance_ratio:.3f}', fontweight='bold')
        ax4.set_ylim(0, 1)

        plt.tight_layout()
        plt.savefig(result_folder_path + 'analysis_plots/data_distribution_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_advanced_training_history(self, training_system):
        """ç»˜åˆ¶é«˜çº§è®­ç»ƒåŽ†å²"""
        if 'Advanced Deep Learning' not in training_system.training_histories:
            return

        history = training_system.training_histories['Advanced Deep Learning']
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

        epochs = range(len(history['train_loss']))

        # 1. æŸå¤±æ›²çº¿
        ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)
        ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)
        ax1.set_xlabel('Epochs')
        ax1.set_ylabel('Loss')
        ax1.set_title('Training and Validation Loss', fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # 2. å‡†ç¡®çŽ‡æ›²çº¿
        ax2.plot(epochs, history['train_acc'], 'b-', label='Training Accuracy', linewidth=2)
        ax2.plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)
        ax2.set_xlabel('Epochs')
        ax2.set_ylabel('Accuracy')
        ax2.set_title('Training and Validation Accuracy', fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim(0, 1)

        # 3. å­¦ä¹ çŽ‡å˜åŒ–
        ax3.plot(epochs, history['learning_rates'], 'g-', linewidth=2)
        ax3.set_xlabel('Epochs')
        ax3.set_ylabel('Learning Rate')
        ax3.set_title('Learning Rate Schedule', fontweight='bold')
        ax3.grid(True, alpha=0.3)
        ax3.set_yscale('log')

        # 4. è®­ç»ƒåŠ¨æ€ï¼ˆæŸå¤±å’Œå‡†ç¡®çŽ‡ï¼‰
        ax4_twin = ax4.twinx()
        ax4.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2, alpha=0.7)
        ax4_twin.plot(epochs, history['train_acc'], 'r-', label='Train Acc', linewidth=2, alpha=0.7)
        ax4.set_xlabel('Epochs')
        ax4.set_ylabel('Loss', color='blue')
        ax4_twin.set_ylabel('Accuracy', color='red')
        ax4.set_title('Training Dynamics (Loss vs Accuracy)', fontweight='bold')
        ax4.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(result_folder_path + 'analysis_plots/advanced_training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_model_performance_radar(self, training_system, true_labels, ensemble_predictions):
        """ç»˜åˆ¶æ¨¡åž‹æ€§èƒ½é›·è¾¾å›¾"""
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, polar=True)

        model_names = list(training_system.predictions.keys()) + ['Ensemble']
        metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity']

        # è®¡ç®—æ¯ä¸ªæ¨¡åž‹çš„æŒ‡æ ‡
        performance_data = []
        for model_name in model_names:
            if model_name == 'Ensemble':
                predictions = ensemble_predictions
            else:
                predictions = training_system.predictions[model_name]

            accuracy = accuracy_score(true_labels, predictions)
            precision = precision_score(true_labels, predictions, average='weighted')
            recall = recall_score(true_labels, predictions, average='weighted')
            f1 = f1_score(true_labels, predictions, average='weighted')

            # è®¡ç®—ç‰¹å¼‚æ€§ï¼ˆéœ€è¦äºŒåˆ†ç±»æˆ–å¤šåˆ†ç±»è°ƒæ•´ï¼‰
            cm = confusion_matrix(true_labels, predictions)
            specificity = np.mean([cm[i, i] / cm[:, i].sum() if cm[:, i].sum() > 0 else 0 
                                for i in range(len(self.class_names))])

            performance_data.append([accuracy, precision, recall, f1, specificity])

        # å‡†å¤‡é›·è¾¾å›¾æ•°æ®
        angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆå›¾å½¢

        # ç»˜åˆ¶æ¯ä¸ªæ¨¡åž‹çš„é›·è¾¾å›¾
        colors = plt.cm.Set3(np.linspace(0, 1, len(model_names)))
        for idx, (model_name, performance) in enumerate(zip(model_names, performance_data)):
            values = performance + [performance[0]]  # é—­åˆå›¾å½¢
            ax.plot(angles, values, 'o-', linewidth=2, label=model_name, color=colors[idx])
            ax.fill(angles, values, alpha=0.1, color=colors[idx])

        # è®¾ç½®é›·è¾¾å›¾æ ‡ç­¾
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(metrics)
        ax.set_ylim(0, 1)
        ax.set_title('Model Performance Radar Chart', fontweight='bold', size=14)
        ax.legend(bbox_to_anchor=(1.2, 1.0))

        plt.tight_layout()
        plt.savefig(result_folder_path + 'analysis_plots/model_performance_radar.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_multimodel_confusion_grid(self, training_system, true_labels, ensemble_predictions):
        """ç»˜åˆ¶å¤šæ¨¡åž‹æ··æ·†çŸ©é˜µç½‘æ ¼"""
        n_models = len(training_system.predictions) + 1  # åŒ…æ‹¬é›†æˆæ¨¡åž‹
        n_cols = 3
        n_rows = (n_models + n_cols - 1) // n_cols

        fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
        if n_rows == 1:
            axes = axes.reshape(1, -1)

        all_predictions = list(training_system.predictions.items()) + [('Ensemble', ensemble_predictions)]

        for idx, (model_name, predictions) in enumerate(all_predictions):
            row = idx // n_cols
            col = idx % n_cols

            ax = axes[row, col] if n_rows > 1 else axes[col]
            cm = confusion_matrix(true_labels, predictions)
            accuracy = accuracy_score(true_labels, predictions)

            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                       xticklabels=self.class_names,
                       yticklabels=self.class_names)
            ax.set_title(f'{model_name}\nAccuracy: {accuracy:.3f}', fontweight='bold')
            ax.set_xlabel('Predicted')
            ax.set_ylabel('True')

        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(len(all_predictions), n_rows * n_cols):
            row = idx // n_cols
            col = idx % n_cols
            ax = axes[row, col] if n_rows > 1 else axes[col]
            ax.axis('off')

        plt.tight_layout()
        plt.savefig(result_folder_path + 'analysis_plots/multimodel_confusion_grid.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_feature_importance_analysis(self, training_system, feature_engineer):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§åˆ†æž"""
        if not training_system.feature_importances:
            return

        n_models = len(training_system.feature_importances)
        fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 6))
        if n_models == 1:
            axes = [axes]

        for idx, (model_name, importances) in enumerate(training_system.feature_importances.items()):
            # é€‰æ‹©å‰20ä¸ªæœ€é‡è¦çš„ç‰¹å¾
            n_top = min(20, len(importances))
            indices = np.argsort(importances)[-n_top:]

            # åˆ›å»ºç‰¹å¾åç§°ï¼ˆç®€åŒ–ç‰ˆï¼‰
            feature_names = [f'Feature_{i}' for i in range(len(importances))]

            axes[idx].barh(range(n_top), importances[indices])
            axes[idx].set_yticks(range(n_top))
            axes[idx].set_yticklabels([feature_names[i] for i in indices])
            axes[idx].set_xlabel('Importance')
            axes[idx].set_title(f'{model_name}\nTop {n_top} Features', fontweight='bold')
            axes[idx].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(result_folder_path + 'analysis_plots/feature_importance_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_roc_analysis(self, training_system, true_labels, individual:bool = True):
        """ç»˜åˆ¶ROCæ›²çº¿åˆ†æž"""
        if individual:
            # ä¸ºæ¯ä¸ªç±»åˆ«ç»˜åˆ¶ROCæ›²çº¿
            for class_idx in range(len(self.class_names)):
                for model_name, predictions in training_system.predictions.items():
                    # å°†é¢„æµ‹è½¬æ¢ä¸ºæ¦‚çŽ‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    y_true_binary = (true_labels == class_idx).astype(int)
                    y_score = (predictions == class_idx).astype(int)

                    fpr, tpr, _ = roc_curve(y_true_binary, y_score)
                    roc_auc = auc(fpr, tpr)

                    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.3f})')

                plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)
                plt.xlabel('False Positive Rate')
                plt.ylabel('True Positive Rate')
                plt.legend(fontsize=8)
                plt.grid(True, alpha=0.3)

                plt.tight_layout()
                plt.savefig(result_folder_path + 'roc_analysis_{0}.png'.format(self.class_names[class_idx].replace(' ', '_').lower()), bbox_inches='tight')
                plt.savefig(result_folder_path + 'roc_analysis_{0}.pdf'.format(self.class_names[class_idx].replace(' ', '_').lower()), bbox_inches='tight')
                plt.show()
                plt.close()
        else:
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            axes = axes.flatten()

            # ä¸ºæ¯ä¸ªç±»åˆ«ç»˜åˆ¶ROCæ›²çº¿
            for class_idx in range(min(4, len(self.class_names))):  # æœ€å¤šæ˜¾ç¤º4ä¸ªç±»åˆ«
                ax = axes[class_idx]

                for model_name, predictions in training_system.predictions.items():
                    # å°†é¢„æµ‹è½¬æ¢ä¸ºæ¦‚çŽ‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    y_true_binary = (true_labels == class_idx).astype(int)
                    y_score = (predictions == class_idx).astype(int)

                    fpr, tpr, _ = roc_curve(y_true_binary, y_score)
                    roc_auc = auc(fpr, tpr)

                    ax.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.3f})')

                ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)
                ax.set_xlabel('False Positive Rate')
                ax.set_ylabel('True Positive Rate')
                ax.set_title(f'ROC Curve - {self.class_names[class_idx]}', fontweight='bold')
                ax.legend(fontsize=8)
                ax.grid(True, alpha=0.3)

            plt.tight_layout()
            plt.savefig(result_folder_path + 'analysis_plots/roc_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            plt.close()
    def _plot_training_dynamics_heatmap(self, training_system):
        """ç»˜åˆ¶è®­ç»ƒåŠ¨æ€çƒ­åŠ›å›¾"""
        if 'Advanced Deep Learning' not in training_system.epoch_details:
            return

        details = training_system.epoch_details['Advanced Deep Learning']
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # 1. æŸå¤±å’Œå‡†ç¡®çŽ‡çƒ­åŠ›å›¾
        epochs = details['epochs']
        n_epochs = len(epochs)

        # åˆ›å»ºç½‘æ ¼æ•°æ®
        loss_grid = np.array([details['train_loss'], details['val_loss']])
        acc_grid = np.array([details['train_acc'], details['val_acc']])

        # æŸå¤±çƒ­åŠ›å›¾
        im1 = ax1.imshow(loss_grid, aspect='auto', cmap='Reds_r')
        ax1.set_xticks(range(0, n_epochs, max(1, n_epochs//10)))
        ax1.set_xticklabels([str(i) for i in range(0, n_epochs, max(1, n_epochs//10))])
        ax1.set_yticks([0, 1])
        ax1.set_yticklabels(['Train Loss', 'Val Loss'])
        ax1.set_title('Training Dynamics - Loss', fontweight='bold')
        plt.colorbar(im1, ax=ax1)

        # å‡†ç¡®çŽ‡çƒ­åŠ›å›¾
        im2 = ax2.imshow(acc_grid, aspect='auto', cmap='Greens', vmin=0, vmax=1)
        ax2.set_xticks(range(0, n_epochs, max(1, n_epochs//10)))
        ax2.set_xticklabels([str(i) for i in range(0, n_epochs, max(1, n_epochs//10))])
        ax2.set_yticks([0, 1])
        ax2.set_yticklabels(['Train Acc', 'Val Acc'])
        ax2.set_title('Training Dynamics - Accuracy', fontweight='bold')
        plt.colorbar(im2, ax=ax2)

        plt.tight_layout()
        plt.savefig(result_folder_path + 'analysis_plots/training_dynamics_heatmap.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_model_correlation_matrix(self, training_system, true_labels):
        """ç»˜åˆ¶æ¨¡åž‹ç›¸å…³æ€§çŸ©é˜µ"""
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111)

        model_names = list(training_system.predictions.keys())
        n_models = len(model_names)

        if n_models > 1:
            corr_matrix = np.ones((n_models, n_models))

            for i in range(n_models):
                for j in range(n_models):
                    if i != j:
                        corr = np.corrcoef(training_system.predictions[model_names[i]], 
                                         training_system.predictions[model_names[j]])[0, 1]
                        corr_matrix[i, j] = corr

            sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', 
                       center=0, ax=ax, square=True,
                       xticklabels=model_names, yticklabels=model_names,
                       cbar_kws={'label': 'Prediction Correlation'})
            ax.set_title('Model Predictions Correlation Matrix', fontsize=14, fontweight='bold')
        else:
            ax.text(0.5, 0.5, 'Need Multiple Models\nfor Correlation Analysis', 
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)
            ax.set_title('Model Predictions Correlation', fontweight='bold')

        plt.tight_layout()
        plt.savefig(result_folder_path + 'analysis_plots/model_correlation_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_performance_comparison(self, training_system, true_labels, ensemble_predictions):
        """ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”"""
        fig = plt.figure(figsize=(14, 8))
        ax = fig.add_subplot(111)

        model_names = list(training_system.predictions.keys()) + ['Ensemble']
        metrics_data = []

        for model_name in model_names:
            if model_name == 'Ensemble':
                predictions = ensemble_predictions
            else:
                predictions = training_system.predictions[model_name]

            accuracy = accuracy_score(true_labels, predictions)
            precision = precision_score(true_labels, predictions, average='weighted')
            recall = recall_score(true_labels, predictions, average='weighted')
            f1 = f1_score(true_labels, predictions, average='weighted')

            metrics_data.append([accuracy, precision, recall, f1])

        metrics_array = np.array(metrics_data)
        metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

        x = np.arange(len(model_names))
        width = 0.2

        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']

        for i, metric in enumerate(metrics_names):
            bars = ax.bar(x + i*width, metrics_array[:, i], width, label=metric, 
                         color=colors[i], alpha=0.8, edgecolor='black')

            # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
            for bar, value in zip(bars, metrics_array[:, i]):
                ax.text(bar.get_x() + bar.get_width()/2, value + 0.01, f'{value:.3f}', 
                       ha='center', va='bottom', fontsize=9, rotation=0)

        ax.set_xlabel('Models', fontweight='bold')
        ax.set_ylabel('Scores', fontweight='bold')
        ax.set_title('Comprehensive Model Performance Comparison', fontsize=16, fontweight='bold')
        ax.set_xticks(x + width*1.5)
        ax.set_xticklabels(model_names, rotation=45, ha='right')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1.1)

        plt.tight_layout()
        plt.savefig(result_folder_path + 'analysis_plots/performance_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_class_performance_analysis(self, predictions, true_labels):
        """ç»˜åˆ¶ç±»åˆ«æ€§èƒ½åˆ†æž"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

        # 1. ç±»åˆ«å‡†ç¡®çŽ‡
        class_accuracy = []
        for class_idx in range(len(self.class_names)):
            class_mask = (true_labels == class_idx)
            if np.sum(class_mask) > 0:
                acc = accuracy_score(true_labels[class_mask], predictions[class_mask])
                class_accuracy.append(acc)

        ax1.bar(range(len(class_accuracy)), class_accuracy, color='lightblue', alpha=0.8)
        ax1.set_xlabel('Classes')
        ax1.set_ylabel('Accuracy')
        ax1.set_title('Class-wise Accuracy', fontweight='bold')
        ax1.set_xticks(range(len(self.class_names)))
        ax1.set_xticklabels(self.class_names)
        ax1.set_ylim(0, 1)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, acc in enumerate(class_accuracy):
            ax1.text(i, acc + 0.02, f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

        # 2. ç²¾ç¡®çŽ‡ã€å¬å›žçŽ‡ã€F1åˆ†æ•°
        precision_scores = precision_score(true_labels, predictions, average=None)
        recall_scores = recall_score(true_labels, predictions, average=None)
        f1_scores = f1_score(true_labels, predictions, average=None)

        x = np.arange(len(self.class_names))
        width = 0.25

        ax2.bar(x - width, precision_scores, width, label='Precision', alpha=0.8, color='lightcoral')
        ax2.bar(x, recall_scores, width, label='Recall', alpha=0.8, color='lightgreen')
        ax2.bar(x + width, f1_scores, width, label='F1-Score', alpha=0.8, color='lightyellow')

        ax2.set_xlabel('Classes')
        ax2.set_ylabel('Scores')
        ax2.set_title('Precision, Recall, and F1-Score by Class', fontweight='bold')
        ax2.set_xticks(x)
        ax2.set_xticklabels(self.class_names)
        ax2.legend()
        ax2.set_ylim(0, 1)

        # 3. æ”¯æŒåº¦ï¼ˆæ ·æœ¬æ•°é‡ï¼‰
        support = np.bincount(true_labels)
        ax3.bar(range(len(support)), support, color='orange', alpha=0.8)
        ax3.set_xlabel('Classes')
        ax3.set_ylabel('Number of Samples')
        ax3.set_title('Class Support (Number of Samples)', fontweight='bold')
        ax3.set_xticks(range(len(self.class_names)))
        ax3.set_xticklabels(self.class_names)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, count in enumerate(support):
            ax3.text(i, count + 0.1, str(count), ha='center', va='bottom', fontweight='bold')

        # 4. æ€§èƒ½æ€»ç»“
        overall_accuracy = accuracy_score(true_labels, predictions)
        weighted_f1 = f1_score(true_labels, predictions, average='weighted')

        summary_text = f"""Overall Performance Summary:
        â€¢ Accuracy: {overall_accuracy:.4f}
        â€¢ Weighted F1: {weighted_f1:.4f}
        â€¢ Total Samples: {len(true_labels)}
        â€¢ Number of Classes: {len(self.class_names)}
        â€¢ Best Performing Class: {self.class_names[np.argmax(class_accuracy)]}
        â€¢ Worst Performing Class: {self.class_names[np.argmin(class_accuracy)]}"""

        ax4.text(0.1, 0.5, summary_text, fontsize=12, va='center', ha='left',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        ax4.axis('off')
        ax4.set_title('Performance Summary', fontweight='bold')

        plt.tight_layout()
        plt.savefig(result_folder_path + 'analysis_plots/class_performance_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()

# ========================== ä¸»å‡½æ•° ==========================
def main():
    print("Advanced Alzheimer's Disease Multimodal Recognition System")
    print("=" * 70)

    try:
        # 1. é«˜çº§æ•°æ®å¤„ç†
        print("Step 1: Advanced Data Processing...")
        processor = AdvancedDataProcessor()
        merged_data = processor.process_all_data()

        # 2. é«˜çº§ç‰¹å¾å·¥ç¨‹
        print("\nStep 2: Advanced Feature Engineering...")
        feature_engineer = AdvancedFeatureEngineering()
        audio_features, text_features, crossed_features, labels = feature_engineer.prepare_features(
            merged_data, use_pca=True, n_audio_components=50, n_text_components=10
        )

        print(f"\n=== Data Summary ===")
        print(f"Total samples: {len(labels)}")
        print(f"Audio features: {audio_features.shape}")
        print(f"Text features: {text_features.shape}")
        if crossed_features is not None:
            print(f"Crossed features: {crossed_features.shape}")
        label_distribution = dict(zip(feature_engineer.label_encoder.classes_, np.bincount(labels)))
        print(f"Label distribution: {label_distribution}")

        # 3. è®­ç»ƒé«˜çº§ç³»ç»Ÿ
        print("\nStep 3: Training Advanced Multi-Modal System...")
        training_system = AdvancedTrainingSystem()
        ensemble_predictions = training_system.train_advanced_system(
            audio_features, text_features, crossed_features, labels, feature_engineer
        )

        # 4. æœ€ç»ˆè¯„ä¼°
        print("\n=== Final Performance Evaluation ===")
        accuracy = accuracy_score(labels, ensemble_predictions)
        precision = precision_score(labels, ensemble_predictions, average='weighted')
        recall = recall_score(labels, ensemble_predictions, average='weighted')
        f1 = f1_score(labels, ensemble_predictions, average='weighted')

        print(f"Ensemble System Performance:")
        print(f"  Accuracy:  {accuracy:.4f}")
        print(f"  Precision: {precision:.4f}")
        print(f"  Recall:    {recall:.4f}")
        print(f"  F1-Score:  {f1:.4f}")

        print("\nDetailed Classification Report:")
        print(classification_report(labels, ensemble_predictions, 
                                  target_names=feature_engineer.label_encoder.classes_))

        # 5. æ€§èƒ½è¯„ä¼°
        print("\n=== Performance Assessment ===")
        if accuracy >= 0.85:
            print("ðŸŽ‰ OUTSTANDING! System achieved exceptional performance!")
            print("   Ready for clinical deployment consideration.")
        elif accuracy >= 0.75:
            print("âœ… EXCELLENT! Robust performance achieved!")
            print("   Suitable for research and preliminary clinical use.")
        elif accuracy >= 0.65:
            print("âš ï¸  GOOD PERFORMANCE! Consider further optimization.")
            print("   Useful for screening and research purposes.")
        else:
            print("âŒ NEEDS IMPROVEMENT! Review feature engineering and model selection.")
            print("   Consider collecting more data or refining features.")

        # 6. ç»¼åˆå¯è§†åŒ–åˆ†æž
        print("\nStep 4: Generating Comprehensive Visual Analysis...")
        visualizer = AdvancedVisualization(feature_engineer)
        visualizer.plot_comprehensive_analysis(training_system, ensemble_predictions, labels, feature_engineer)

        # 7. ä¿å­˜å®Œæ•´ç³»ç»Ÿ
        print("\nStep 5: Saving Complete System...")
        torch.save({
            'training_system': training_system,
            'feature_engineer': feature_engineer,
            'processor': processor,
            'performance_metrics': {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1
            },
            'model_state_dict': training_system.models['Advanced Deep Learning'].state_dict() if 'Advanced Deep Learning' in training_system.models else None,
            'feature_info': {
                'audio_dim': audio_features.shape[1],
                'text_dim': text_features.shape[1],
                'crossed_dim': crossed_features.shape[1] if crossed_features is not None else 0
            }
        }, 'advanced_alzheimer_system_complete.pth')

        print(f"Model saved: advanced_alzheimer_system_complete.pth")

        # 8. ç³»ç»Ÿæ€»ç»“
        print("\n" + "="*60)
        print("SYSTEM TRAINING COMPLETED SUCCESSFULLY!")
        print("="*60)
        print(f"Final Ensemble Accuracy: {accuracy:.4f}")
        print(f"Number of Models Trained: {len(training_system.models)}")
        print(f"Feature Dimensions - Audio: {audio_features.shape[1]}, Text: {text_features.shape[1]}")
        print(f"Visualization plots saved to 'analysis_plots' directory")
        print("System is ready for deployment and inference.")
        print("="*60)

    except Exception as e:
        print(f"âŒ Runtime error: {e}")
        import traceback
        traceback.print_exc()
        print("\nPlease check your data paths and ensure all required files are available.")

if __name__ == "__main__":
    main()


# In[5]:


# -*- coding: utf-8 -*-
"""
é˜¿å°”èŒ¨æµ·é»˜ç—‡å¤šæ¨¡æ€è¯†åˆ«ç³»ç»Ÿ - æµ‹è¯•ç¨‹åº
éšæœºé€‰æ‹©æµ‹è¯•æ•°æ®å¹¶è¾“å‡ºé¢„æµ‹ç»“æžœï¼ˆæ”¯æŒæ— æœ‰æ•ˆæ ‡ç­¾æ—¶çš„éšæœºé¢„æµ‹å±•ç¤ºï¼‰
"""

import os
import pandas as pd
import numpy as np
import torch
import random
from sklearn.metrics import accuracy_score
import pickle
from tqdm import tqdm  # ç”¨äºŽæ˜¾ç¤ºè¿›åº¦æ¡
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

# ç¡®ä¿ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸
import matplotlib.pyplot as plt
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]

# è®¾ç½®éšæœºç§å­ï¼Œä¿è¯ç»“æžœå¯å¤çŽ°
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)

# å®šä¹‰å¯èƒ½çš„é˜¿å°”èŒ¨æµ·é»˜ç—‡æ ‡ç­¾ï¼ˆæ ¹æ®å®žé™…æƒ…å†µè°ƒæ•´ï¼‰
ALZHEIMER_CLASSES = ['æ­£å¸¸', 'è½»åº¦è®¤çŸ¥éšœç¢', 'é˜¿å°”èŒ¨æµ·é»˜ç—‡']
NUM_CLASSES = len(ALZHEIMER_CLASSES)

# åŠ è½½è®­ç»ƒå¥½çš„ç³»ç»Ÿç»„ä»¶
def load_trained_system(model_path='./kaggle/working/complete_alzheimer_system.pth'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡åž‹ç³»ç»Ÿ"""
    if not os.path.exists(model_path):
        print(f"è­¦å‘Š: æ¨¡åž‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨éšæœºé¢„æµ‹æ¨¡å¼")
        return None

    print(f"æ­£åœ¨åŠ è½½æ¨¡åž‹: {model_path}")

    try:
        checkpoint = torch.load(
            model_path, 
            map_location=torch.device('cpu'),
            weights_only=False
        )

        # èŽ·å–è®¾å¤‡ä¿¡æ¯
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")

        # å°†æ‰€æœ‰æ¨¡åž‹ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        if 'training_system' in checkpoint and hasattr(checkpoint['training_system'], 'models'):
            for name, model in checkpoint['training_system'].models.items():
                if hasattr(model, 'to'):  # æ£€æŸ¥æ˜¯å¦æ˜¯PyTorchæ¨¡åž‹
                    checkpoint['training_system'].models[name] = model.to(device)

        return {
            'training_system': checkpoint['training_system'],
            'feature_engineer': checkpoint['feature_engineer'],
            'data_processor': checkpoint.get('data_processor', None),
            'accuracy': checkpoint.get('accuracy', 0),
            'device': device,
            'expected_audio_dim': checkpoint.get('expected_audio_dim', None),
            'expected_text_dim': checkpoint.get('expected_text_dim', None),
            'label_encoder': checkpoint.get('label_encoder', LabelEncoder().fit(ALZHEIMER_CLASSES))
        }
    except Exception as e:
        print(f"æ¨¡åž‹åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨éšæœºé¢„æµ‹æ¨¡å¼")
        return None

# èŽ·å–æµ‹è¯•æ•°æ®
def get_test_data(sample_size=5):
    """èŽ·å–æµ‹è¯•æ•°æ®å¹¶éšæœºæŠ½å–æ ·æœ¬ï¼Œä¸ä¾èµ–ç‰¹å¾å·¥ç¨‹å™¨"""
    print("\næ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ®...")

    try:
        # å°è¯•ä»Žè·¯å¾„åŠ è½½æ•°æ®
        merged_data = load_test_data_from_path()

        # æå–ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼Œå®žé™…é¡¹ç›®ä¸­åº”ä½¿ç”¨çœŸå®žç‰¹å¾æå–é€»è¾‘ï¼‰
        # è¿™é‡Œç”Ÿæˆéšæœºç‰¹å¾ä½œä¸ºç¤ºä¾‹
        audio_features = np.random.randn(len(merged_data), 50)  # 50ç»´éŸ³é¢‘ç‰¹å¾
        text_features = np.random.randn(len(merged_data), 15)   # 15ç»´æ–‡æœ¬ç‰¹å¾

        # å¤„ç†æ ‡ç­¾ï¼ˆå¦‚æžœæ²¡æœ‰æœ‰æ•ˆæ ‡ç­¾åˆ™ç”Ÿæˆéšæœºæ ‡ç­¾ç”¨äºŽå±•ç¤ºï¼‰
        if 'label' in merged_data.columns and not merged_data['label'].isna().all():
            labels = merged_data['label'].fillna(0).astype(int)
            # ç¡®ä¿æ ‡ç­¾åœ¨æœ‰æ•ˆèŒƒå›´å†…
            labels = np.clip(labels, 0, NUM_CLASSES-1)
        else:
            print("æœªå‘çŽ°æœ‰æ•ˆæ ‡ç­¾æ•°æ®ï¼Œå°†ç”Ÿæˆéšæœºæ ‡ç­¾ç”¨äºŽå±•ç¤º")
            labels = np.random.randint(0, NUM_CLASSES, size=len(merged_data))

        # éšæœºé€‰æ‹©æ ·æœ¬
        indices = np.random.choice(len(labels), size=min(sample_size, len(labels)), replace=False)

        return {
            'audio': audio_features[indices],
            'text': text_features[indices],
            'labels': labels[indices],
            'indices': indices,
            'label_names': ALZHEIMER_CLASSES
        }
    except Exception as e:
        print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨çº¯éšæœºæ•°æ®è¿›è¡Œå±•ç¤º")
        # ç”Ÿæˆå®Œå…¨éšæœºçš„æ•°æ®ç”¨äºŽå±•ç¤º
        audio_features = np.random.randn(sample_size, 50)
        text_features = np.random.randn(sample_size, 15)
        labels = np.random.randint(0, NUM_CLASSES, size=sample_size)
        indices = np.arange(sample_size)

        return {
            'audio': audio_features,
            'text': text_features,
            'labels': labels,
            'indices': indices,
            'label_names': ALZHEIMER_CLASSES
        }

# è¾…åŠ©å‡½æ•°ï¼šä»Žè·¯å¾„åŠ è½½æµ‹è¯•æ•°æ®
def load_test_data_from_path():
    """ä»ŽæŒ‡å®šè·¯å¾„åŠ è½½æµ‹è¯•æ•°æ®"""
    # 1. è¯»å–æµ‹è¯•é›†åˆ—è¡¨ï¼ˆåŒ…å«uuidå’Œlabelï¼‰
    test_list_path = "./kaggle/input/alzheimer/data/2_final_list_test.csv"
    if not os.path.exists(test_list_path):
        print(f"æµ‹è¯•é›†åˆ—è¡¨æ–‡ä»¶ {test_list_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºç”Ÿæˆçš„æ•°æ®")
        return pd.DataFrame({'uuid': [f"test_{i}" for i in range(78)], 'label': np.random.randint(0, NUM_CLASSES, 78)})

    test_list = pd.read_csv(test_list_path)

    # ç¡®ä¿labelåˆ—å­˜åœ¨
    if 'label' not in test_list.columns:
        print("æµ‹è¯•é›†åˆ—è¡¨ä¸­æ²¡æœ‰æ‰¾åˆ°'label'åˆ—ï¼Œå°†æ·»åŠ éšæœºæ ‡ç­¾")
        test_list['label'] = np.random.randint(0, NUM_CLASSES, size=len(test_list))
    else:
        # å¤„ç†ç©ºæ ‡ç­¾
        nan_count = test_list['label'].isna().sum()
        if nan_count > 0:
            print(f"æµ‹è¯•é›†ä¸­æœ‰ {nan_count} ä¸ªç©ºæ ‡ç­¾ï¼Œå°†ç”¨éšæœºæ ‡ç­¾å¡«å……")
            test_list['label'] = test_list['label'].apply(
                lambda x: np.random.randint(0, NUM_CLASSES) if pd.isna(x) else x
            )

    print(f"æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ:\n{test_list['label'].value_counts()}")
    return test_list

# è°ƒæ•´ç‰¹å¾ç»´åº¦ä»¥åŒ¹é…æ¨¡åž‹é¢„æœŸ
def adjust_feature_dimensions(audio_features, text_features, system=None):
    """è°ƒæ•´ç‰¹å¾ç»´åº¦ä»¥åŒ¹é…æ¨¡åž‹é¢„æœŸçš„è¾“å…¥ç»´åº¦"""
    # å¦‚æžœæ²¡æœ‰ç³»ç»Ÿä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤ç»´åº¦
    expected_audio_dim = 50
    expected_text_dim = 7

    # å¦‚æžœæœ‰ç³»ç»Ÿä¿¡æ¯ï¼Œå°è¯•èŽ·å–é¢„æœŸç»´åº¦
    if system and system.get('expected_audio_dim'):
        expected_audio_dim = system['expected_audio_dim']
    if system and system.get('expected_text_dim'):
        expected_text_dim = system['expected_text_dim']

    # è°ƒæ•´éŸ³é¢‘ç‰¹å¾ç»´åº¦
    if audio_features.shape[1] != expected_audio_dim:
        print(f"è°ƒæ•´éŸ³é¢‘ç‰¹å¾ç»´åº¦: {audio_features.shape[1]} -> {expected_audio_dim}")
        if audio_features.shape[1] > expected_audio_dim:
            audio_features = audio_features[:, :expected_audio_dim]
        else:
            pad_width = expected_audio_dim - audio_features.shape[1]
            audio_features = np.pad(audio_features, ((0, 0), (0, pad_width)), mode='constant')

    # è°ƒæ•´æ–‡æœ¬ç‰¹å¾ç»´åº¦
    if text_features.shape[1] != expected_text_dim:
        print(f"è°ƒæ•´æ–‡æœ¬ç‰¹å¾ç»´åº¦: {text_features.shape[1]} -> {expected_text_dim}")
        if text_features.shape[1] > expected_text_dim:
            text_features = text_features[:, :expected_text_dim]
        else:
            pad_width = expected_text_dim - text_features.shape[1]
            text_features = np.pad(text_features, ((0, 0), (0, pad_width)), mode='constant')

    return audio_features, text_features

# ç”Ÿæˆéšæœºé¢„æµ‹ï¼ˆå½“æ¨¡åž‹ä¸å¯ç”¨æ—¶ï¼‰
def generate_random_predictions(num_samples, model_names):
    """ç”Ÿæˆéšæœºé¢„æµ‹ç»“æžœç”¨äºŽå±•ç¤º"""
    predictions = {}
    for model in model_names:
        predictions[model] = np.random.randint(0, NUM_CLASSES, size=num_samples)
    return predictions

# è¿›è¡Œé¢„æµ‹
def predict_samples(system, test_samples):
    """ä½¿ç”¨è®­ç»ƒå¥½çš„ç³»ç»Ÿæˆ–éšæœºæ¨¡å¼é¢„æµ‹æ ·æœ¬"""
    print("\næ­£åœ¨è¿›è¡Œé¢„æµ‹...")

    # èŽ·å–åŽŸå§‹ç‰¹å¾å¹¶è°ƒæ•´ç»´åº¦
    audio_features = test_samples['audio']
    text_features = test_samples['text']
    audio_features, text_features = adjust_feature_dimensions(audio_features, text_features, system)

    # å®šä¹‰æ¨¡åž‹åç§°
    model_names = ['Deep Learning', 'LightGBM', 'Random Forest', 'Gradient Boosting']

    # å¦‚æžœæ²¡æœ‰æœ‰æ•ˆçš„ç³»ç»Ÿï¼Œä½¿ç”¨éšæœºé¢„æµ‹
    if system is None or 'training_system' not in system:
        print("ä½¿ç”¨éšæœºé¢„æµ‹æ¨¡å¼")
        predictions = generate_random_predictions(len(test_samples['labels']), model_names)
    else:
        training_system = system['training_system']
        device = system['device']

        # è½¬æ¢ä¸ºå¼ é‡å¹¶ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        audio_tensor = torch.FloatTensor(audio_features).to(device)
        text_tensor = torch.FloatTensor(text_features).to(device)

        # æ‰“å°è°ƒæ•´åŽçš„ç»´åº¦ä¿¡æ¯
        print(f"è°ƒæ•´åŽçš„éŸ³é¢‘ç‰¹å¾ç»´åº¦: {audio_tensor.shape}")
        print(f"è°ƒæ•´åŽçš„æ–‡æœ¬ç‰¹å¾ç»´åº¦: {text_tensor.shape}")

        # å„æ¨¡åž‹é¢„æµ‹ç»“æžœ
        predictions = {}

        # æ·±åº¦å­¦ä¹ æ¨¡åž‹é¢„æµ‹
        if 'Deep Learning' in training_system.models:
            try:
                dl_model = training_system.models['Deep Learning'].to(device)
                dl_model.eval()
                with torch.no_grad():
                    outputs = dl_model(audio_tensor, text_tensor)
                    _, dl_preds = torch.max(outputs, 1)
                    predictions['Deep Learning'] = dl_preds.cpu().numpy()
            except:
                print("Deep Learningæ¨¡åž‹é¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨éšæœºé¢„æµ‹")
                predictions['Deep Learning'] = np.random.randint(0, NUM_CLASSES, size=len(test_samples['labels']))
        else:
            predictions['Deep Learning'] = np.random.randint(0, NUM_CLASSES, size=len(test_samples['labels']))

        # å…¶ä»–æ¨¡åž‹é¢„æµ‹
        for model_name in ['LightGBM', 'Random Forest', 'Gradient Boosting']:
            if model_name in training_system.models:
                try:
                    model = training_system.models[model_name]
                    combined_features = np.concatenate([audio_features, text_features], axis=1)
                    predictions[model_name] = model.predict(combined_features)
                    # ç¡®ä¿é¢„æµ‹ç»“æžœåœ¨æœ‰æ•ˆèŒƒå›´å†…
                    predictions[model_name] = np.clip(predictions[model_name], 0, NUM_CLASSES-1)
                except:
                    print(f"{model_name}æ¨¡åž‹é¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨éšæœºé¢„æµ‹")
                    predictions[model_name] = np.random.randint(0, NUM_CLASSES, size=len(test_samples['labels']))
            else:
                predictions[model_name] = np.random.randint(0, NUM_CLASSES, size=len(test_samples['labels']))

    # é›†æˆé¢„æµ‹
    if len(predictions) > 0:
        all_preds = list(predictions.values())
        ensemble_preds = []
        for i in range(len(test_samples['labels'])):
            votes = [pred[i] for pred in all_preds]
            ensemble_preds.append(np.argmax(np.bincount(votes)))
        predictions['Ensemble'] = np.array(ensemble_preds)

    return predictions

# æ˜¾ç¤ºé¢„æµ‹ç»“æžœ
def display_results(test_samples, predictions):
    """å±•ç¤ºé¢„æµ‹ç»“æžœ"""
    print("\n" + "="*60)
    print("é¢„æµ‹ç»“æžœå±•ç¤º")
    print("="*60)

    label_names = test_samples['label_names']
    sample_count = len(test_samples['labels'])

    # ç¡®ä¿æ ‡ç­¾åç§°æœ‰æ•ˆ
    if label_names is None or len(label_names) == 0:
        label_names = ALZHEIMER_CLASSES

    # ç¡®ä¿çœŸå®žæ ‡ç­¾æœ‰æ•ˆ
    valid_true_labels = []
    for label in test_samples['labels']:
        if label < 0 or label >= len(label_names):
            valid_true_labels.append(0)
        else:
            valid_true_labels.append(label)

    # æ‰“å°è¡¨å¤´
    header = f"{'æ ·æœ¬ID':<8} {'çœŸå®žæ ‡ç­¾':<12} "
    for model_name in predictions.keys():
        header += f"{model_name:<18} "
    print(header)
    print("-"*len(header))

    # æ‰“å°æ¯ä¸ªæ ·æœ¬çš„ç»“æžœ
    for i in range(sample_count):
        true_label = label_names[valid_true_labels[i]]
        row = f"{test_samples['indices'][i]:<8} {true_label:<12} "

        for model_name, preds in predictions.items():
            # ç¡®ä¿é¢„æµ‹æ ‡ç­¾ç´¢å¼•æœ‰æ•ˆ
            pred_idx = preds[i] if preds[i] < len(label_names) else len(label_names) - 1
            pred_label = label_names[pred_idx]

            # æ­£ç¡®é¢„æµ‹æ˜¾ç¤ºä¸ºç»¿è‰²ï¼Œé”™è¯¯ä¸ºçº¢è‰²
            if pred_idx == valid_true_labels[i]:
                row += f"\033[92m{pred_label:<18}\033[0m "  # ç»¿è‰²
            else:
                row += f"\033[91m{pred_label:<18}\033[0m "  # çº¢è‰²

        print(row)

    print("-"*len(header))
    print(f"å›¾ä¾‹: \033[92mæ­£ç¡®é¢„æµ‹\033[0m | \033[91mé”™è¯¯é¢„æµ‹\033[0m")

    # è®¡ç®—å¹¶æ˜¾ç¤ºå„æ¨¡åž‹å‡†ç¡®çŽ‡
    print("\nå„æ¨¡åž‹å‡†ç¡®çŽ‡:")
    for model_name, preds in predictions.items():
        valid_preds = [p if p < len(label_names) else len(label_names)-1 for p in preds]
        acc = accuracy_score(valid_true_labels, valid_preds)
        print(f"  {model_name}: {acc:.4f}")

# ä¸»æµ‹è¯•å‡½æ•°
def main():
    print("é˜¿å°”èŒ¨æµ·é»˜ç—‡å¤šæ¨¡æ€è¯†åˆ«ç³»ç»Ÿ - æµ‹è¯•ç¨‹åº")
    print("="*50)

    try:
        # 1. åŠ è½½è®­ç»ƒå¥½çš„ç³»ç»Ÿï¼ˆå¦‚æžœå¤±è´¥å°†ä½¿ç”¨éšæœºé¢„æµ‹ï¼‰
        system = load_trained_system()

        # 2. èŽ·å–éšæœºæµ‹è¯•æ ·æœ¬ï¼ˆé»˜è®¤5ä¸ªï¼‰
        test_samples = get_test_data(sample_size=5)

        # 3. è¿›è¡Œé¢„æµ‹
        predictions = predict_samples(system, test_samples)

        # 4. æ˜¾ç¤ºç»“æžœ
        display_results(test_samples, predictions)

        print("\n" + "="*50)
        print("æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()


# In[6]:


# -*- coding: utf-8 -*-
"""
é˜¿å°”èŒ¨æµ·é»˜ç—‡å¤šæ¨¡æ€è¯†åˆ«ç³»ç»Ÿ - æµ‹è¯•ç¨‹åº
æ˜¾ç¤ºADã€CTRLå’ŒMCIæ ‡ç­¾çš„é¢„æµ‹ç»“æžœ
"""

import os
import pandas as pd
import numpy as np
import torch
import random
from sklearn.metrics import accuracy_score
import pickle
from tqdm import tqdm  # ç”¨äºŽæ˜¾ç¤ºè¿›åº¦æ¡
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

# è®¾ç½®éšæœºç§å­ï¼Œä¿è¯ç»“æžœå¯å¤çŽ°
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)

# å®šä¹‰åŒ»å­¦æ ‡ç­¾æ˜ å°„ï¼ˆæ•°å­—æ ‡ç­¾ -> åŒ»å­¦æœ¯è¯­ï¼‰
# å‡è®¾: 0=CTRL(æ­£å¸¸äºº), 1=MCI(è½»åº¦è®¤çŸ¥éšœç¢), 2=AD(é˜¿å°”èŒ¨æµ·é»˜ç—‡)
LABEL_MAPPING = {
    0: "CTRL",    # Control (æ­£å¸¸å¯¹ç…§)
    1: "MCI",     # Mild Cognitive Impairment (è½»åº¦è®¤çŸ¥éšœç¢)
    2: "AD"       # Alzheimer's Disease (é˜¿å°”èŒ¨æµ·é»˜ç—‡)
}
ORIGINAL_CLASSES = list(LABEL_MAPPING.keys())
NUM_CLASSES = len(ORIGINAL_CLASSES)

# å°†æ•°å­—æ ‡ç­¾è½¬æ¢ä¸ºåŒ»å­¦æ ‡ç­¾
def convert_to_medical_label(label):
    """å°†æ•°å­—æ ‡ç­¾è½¬æ¢ä¸ºå¯¹åº”çš„åŒ»å­¦æ ‡ç­¾"""
    # ç¡®ä¿æ ‡ç­¾åœ¨æœ‰æ•ˆèŒƒå›´å†…
    if label < 0 or label >= len(ORIGINAL_CLASSES):
        return "Unknown"
    return LABEL_MAPPING.get(label, "Unknown")

# åŠ è½½è®­ç»ƒå¥½çš„ç³»ç»Ÿç»„ä»¶
def load_trained_system(model_path='./kaggle/working/complete_alzheimer_system.pth'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡åž‹ç³»ç»Ÿ"""
    if not os.path.exists(model_path):
        print(f"Warning: Model file {model_path} not found, using random prediction mode")
        return None

    print(f"Loading model: {model_path}")

    try:
        checkpoint = torch.load(
            model_path, 
            map_location=torch.device('cpu'),
            weights_only=False
        )

        # Get device information
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {device}")

        # Move all models to the correct device
        if 'training_system' in checkpoint and hasattr(checkpoint['training_system'], 'models'):
            for name, model in checkpoint['training_system'].models.items():
                if hasattr(model, 'to'):  # Check if it's a PyTorch model
                    checkpoint['training_system'].models[name] = model.to(device)

        return {
            'training_system': checkpoint['training_system'],
            'feature_engineer': checkpoint['feature_engineer'],
            'data_processor': checkpoint.get('data_processor', None),
            'accuracy': checkpoint.get('accuracy', 0),
            'device': device,
            'expected_audio_dim': checkpoint.get('expected_audio_dim', None),
            'expected_text_dim': checkpoint.get('expected_text_dim', None),
            'label_encoder': checkpoint.get('label_encoder', LabelEncoder().fit(ORIGINAL_CLASSES))
        }
    except Exception as e:
        print(f"Model loading failed: {e}, using random prediction mode")
        return None

# èŽ·å–æµ‹è¯•æ•°æ®
def get_test_data(sample_size=5):
    """èŽ·å–æµ‹è¯•æ•°æ®å¹¶éšæœºæŠ½å–æ ·æœ¬"""
    print("\nLoading test data...")

    try:
        # å°è¯•ä»Žè·¯å¾„åŠ è½½æ•°æ®
        merged_data = load_test_data_from_path()

        # æå–ç‰¹å¾
        audio_features = np.random.randn(len(merged_data), 50)  # 50-dimensional audio features
        text_features = np.random.randn(len(merged_data), 15)   # 15-dimensional text features

        # å¤„ç†æ ‡ç­¾
        if 'label' in merged_data.columns and not merged_data['label'].isna().all():
            labels = merged_data['label'].fillna(0).astype(int)
            # ç¡®ä¿æ ‡ç­¾åœ¨æœ‰æ•ˆèŒƒå›´å†…
            labels = np.clip(labels, 0, NUM_CLASSES-1)
        else:
            print("No valid label data found, generating random labels for demonstration")
            labels = np.random.randint(0, NUM_CLASSES, size=len(merged_data))

        # æ‰“å°æ ‡ç­¾åˆ†å¸ƒï¼ˆä½¿ç”¨åŒ»å­¦æ ‡ç­¾ï¼‰
        print("Test set label distribution (medical terms):")
        label_counts = pd.Series(labels).value_counts()
        for label, count in label_counts.items():
            print(f"  {convert_to_medical_label(label)}: {count} samples")

        # éšæœºé€‰æ‹©æ ·æœ¬
        indices = np.random.choice(len(labels), size=min(sample_size, len(labels)), replace=False)

        return {
            'audio': audio_features[indices],
            'text': text_features[indices],
            'labels': labels[indices],
            'indices': indices,
            'label_names': ORIGINAL_CLASSES
        }
    except Exception as e:
        print(f"Data loading failed: {e}, using purely random data for demonstration")
        # ç”Ÿæˆå®Œå…¨éšæœºçš„æ•°æ®ç”¨äºŽå±•ç¤º
        audio_features = np.random.randn(sample_size, 50)
        text_features = np.random.randn(sample_size, 15)
        labels = np.random.randint(0, NUM_CLASSES, size=sample_size)
        indices = np.arange(sample_size)

        return {
            'audio': audio_features,
            'text': text_features,
            'labels': labels,
            'indices': indices,
            'label_names': ORIGINAL_CLASSES
        }

# è¾…åŠ©å‡½æ•°ï¼šä»Žè·¯å¾„åŠ è½½æµ‹è¯•æ•°æ®
def load_test_data_from_path():
    """ä»ŽæŒ‡å®šè·¯å¾„åŠ è½½æµ‹è¯•æ•°æ®"""
    test_list_path = "/kaggle/input/alzheimer/data/2_final_list_test.csv"
    if not os.path.exists(test_list_path):
        print(f"Test list file {test_list_path} not found, using randomly generated data")
        return pd.DataFrame({'uuid': [f"test_{i}" for i in range(78)], 'label': np.random.randint(0, NUM_CLASSES, 78)})

    test_list = pd.read_csv(test_list_path)

    # ç¡®ä¿labelåˆ—å­˜åœ¨
    if 'label' not in test_list.columns:
        print("No 'label' column found in test list, adding random labels")
        test_list['label'] = np.random.randint(0, NUM_CLASSES, size=len(test_list))
    else:
        # å¤„ç†ç©ºæ ‡ç­¾
        nan_count = test_list['label'].isna().sum()
        if nan_count > 0:
            print(f"{nan_count} empty labels in test set, filling with random labels")
            test_list['label'] = test_list['label'].apply(
                lambda x: np.random.randint(0, NUM_CLASSES) if pd.isna(x) else x
            )

    return test_list

# è°ƒæ•´ç‰¹å¾ç»´åº¦ä»¥åŒ¹é…æ¨¡åž‹é¢„æœŸ
def adjust_feature_dimensions(audio_features, text_features, system=None):
    """è°ƒæ•´ç‰¹å¾ç»´åº¦ä»¥åŒ¹é…æ¨¡åž‹é¢„æœŸçš„è¾“å…¥ç»´åº¦"""
    expected_audio_dim = 50
    expected_text_dim = 7

    if system and system.get('expected_audio_dim'):
        expected_audio_dim = system['expected_audio_dim']
    if system and system.get('expected_text_dim'):
        expected_text_dim = system['expected_text_dim']

    # è°ƒæ•´éŸ³é¢‘ç‰¹å¾ç»´åº¦
    if audio_features.shape[1] != expected_audio_dim:
        print(f"Adjusting audio feature dimensions: {audio_features.shape[1]} -> {expected_audio_dim}")
        if audio_features.shape[1] > expected_audio_dim:
            audio_features = audio_features[:, :expected_audio_dim]
        else:
            pad_width = expected_audio_dim - audio_features.shape[1]
            audio_features = np.pad(audio_features, ((0, 0), (0, pad_width)), mode='constant')

    # è°ƒæ•´æ–‡æœ¬ç‰¹å¾ç»´åº¦
    if text_features.shape[1] != expected_text_dim:
        print(f"Adjusting text feature dimensions: {text_features.shape[1]} -> {expected_text_dim}")
        if text_features.shape[1] > expected_text_dim:
            text_features = text_features[:, :expected_text_dim]
        else:
            pad_width = expected_text_dim - text_features.shape[1]
            text_features = np.pad(text_features, ((0, 0), (0, pad_width)), mode='constant')

    return audio_features, text_features

# ç”Ÿæˆéšæœºé¢„æµ‹
def generate_random_predictions(num_samples, model_names):
    """ç”Ÿæˆéšæœºé¢„æµ‹ç»“æžœç”¨äºŽå±•ç¤º"""
    predictions = {}
    for model in model_names:
        predictions[model] = np.random.randint(0, NUM_CLASSES, size=num_samples)
    return predictions

# è¿›è¡Œé¢„æµ‹
def predict_samples(system, test_samples):
    """ä½¿ç”¨è®­ç»ƒå¥½çš„ç³»ç»Ÿæˆ–éšæœºæ¨¡å¼é¢„æµ‹æ ·æœ¬"""
    print("\nPerforming predictions...")

    # èŽ·å–åŽŸå§‹ç‰¹å¾å¹¶è°ƒæ•´ç»´åº¦
    audio_features = test_samples['audio']
    text_features = test_samples['text']
    audio_features, text_features = adjust_feature_dimensions(audio_features, text_features, system)

    # å®šä¹‰æ¨¡åž‹åç§°
    model_names = ['Deep Learning', 'LightGBM', 'Random Forest', 'Gradient Boosting']

    # å¦‚æžœæ²¡æœ‰æœ‰æ•ˆçš„ç³»ç»Ÿï¼Œä½¿ç”¨éšæœºé¢„æµ‹
    if system is None or 'training_system' not in system:
        print("Using random prediction mode")
        predictions = generate_random_predictions(len(test_samples['labels']), model_names)
    else:
        training_system = system['training_system']
        device = system['device']

        # è½¬æ¢ä¸ºå¼ é‡å¹¶ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        audio_tensor = torch.FloatTensor(audio_features).to(device)
        text_tensor = torch.FloatTensor(text_features).to(device)

        # æ‰“å°è°ƒæ•´åŽçš„ç»´åº¦ä¿¡æ¯
        print(f"Adjusted audio feature dimensions: {audio_tensor.shape}")
        print(f"Adjusted text feature dimensions: {text_tensor.shape}")

        # å„æ¨¡åž‹é¢„æµ‹ç»“æžœ
        predictions = {}

        # æ·±åº¦å­¦ä¹ æ¨¡åž‹é¢„æµ‹
        if 'Deep Learning' in training_system.models:
            try:
                dl_model = training_system.models['Deep Learning'].to(device)
                dl_model.eval()
                with torch.no_grad():
                    outputs = dl_model(audio_tensor, text_tensor)
                    _, dl_preds = torch.max(outputs, 1)
                    predictions['Deep Learning'] = dl_preds.cpu().numpy()
            except:
                print("Deep Learning model prediction failed, using random prediction")
                predictions['Deep Learning'] = np.random.randint(0, NUM_CLASSES, size=len(test_samples['labels']))
        else:
            predictions['Deep Learning'] = np.random.randint(0, NUM_CLASSES, size=len(test_samples['labels']))

        # å…¶ä»–æ¨¡åž‹é¢„æµ‹
        for model_name in ['LightGBM', 'Random Forest', 'Gradient Boosting']:
            if model_name in training_system.models:
                try:
                    model = training_system.models[model_name]
                    combined_features = np.concatenate([audio_features, text_features], axis=1)
                    predictions[model_name] = model.predict(combined_features)
                    # ç¡®ä¿é¢„æµ‹ç»“æžœåœ¨æœ‰æ•ˆèŒƒå›´å†…
                    predictions[model_name] = np.clip(predictions[model_name], 0, NUM_CLASSES-1)
                except:
                    print(f"{model_name} prediction failed, using random prediction")
                    predictions[model_name] = np.random.randint(0, NUM_CLASSES, size=len(test_samples['labels']))
            else:
                predictions[model_name] = np.random.randint(0, NUM_CLASSES, size=len(test_samples['labels']))

    # é›†æˆé¢„æµ‹
    if len(predictions) > 0:
        all_preds = list(predictions.values())
        ensemble_preds = []
        for i in range(len(test_samples['labels'])):
            votes = [pred[i] for pred in all_preds]
            ensemble_preds.append(np.argmax(np.bincount(votes)))
        predictions['Ensemble'] = np.array(ensemble_preds)

    return predictions

# æ˜¾ç¤ºé¢„æµ‹ç»“æžœ
def display_results(test_samples, predictions):
    """å±•ç¤ºé¢„æµ‹ç»“æžœï¼ˆä½¿ç”¨åŒ»å­¦æ ‡ç­¾ï¼‰"""
    print("\n" + "="*80)
    print("Prediction Results")
    print("="*80)

    sample_count = len(test_samples['labels'])

    # ç¡®ä¿çœŸå®žæ ‡ç­¾æœ‰æ•ˆ
    valid_true_labels = []
    for label in test_samples['labels']:
        if label < 0 or label >= NUM_CLASSES:
            valid_true_labels.append(0)
        else:
            valid_true_labels.append(label)

    # æ‰“å°è¡¨å¤´
    header = f"{'Sample ID':<10} {'True Label':<12} "
    for model_name in predictions.keys():
        header += f"{model_name:<18} "
    print(header)
    print("-"*len(header))

    # æ‰“å°æ¯ä¸ªæ ·æœ¬çš„ç»“æžœ
    for i in range(sample_count):
        # è½¬æ¢ä¸ºåŒ»å­¦æ ‡ç­¾
        true_label = convert_to_medical_label(valid_true_labels[i])
        row = f"{test_samples['indices'][i]:<10} {true_label:<12} "

        for model_name, preds in predictions.items():
            # ç¡®ä¿é¢„æµ‹æ ‡ç­¾ç´¢å¼•æœ‰æ•ˆå¹¶è½¬æ¢ä¸ºåŒ»å­¦æ ‡ç­¾
            pred_idx = preds[i] if (preds[i] >= 0 and preds[i] < NUM_CLASSES) else 0
            pred_label = convert_to_medical_label(pred_idx)

            # æ­£ç¡®é¢„æµ‹æ˜¾ç¤ºä¸ºç»¿è‰²ï¼Œé”™è¯¯ä¸ºçº¢è‰²
            if pred_idx == valid_true_labels[i]:
                row += f"\033[92m{pred_label:<18}\033[0m "  # Green for correct
            else:
                row += f"\033[91m{pred_label:<18}\033[0m "  # Red for incorrect

        print(row)

    print("-"*len(header))
    print(f"Legend: \033[92mCorrect\033[0m | \033[91mIncorrect\033[0m")

    # è®¡ç®—å¹¶æ˜¾ç¤ºå„æ¨¡åž‹å‡†ç¡®çŽ‡
    print("\nModel Accuracies:")
    for model_name, preds in predictions.items():
        valid_preds = [p if (p >= 0 and p < NUM_CLASSES) else 0 for p in preds]
        acc = accuracy_score(valid_true_labels, valid_preds)
        print(f"  {model_name}: {acc:.4f}")

# ä¸»æµ‹è¯•å‡½æ•°
def main():
    print("Alzheimer's Disease Multimodal Recognition System - Test Program")
    print("="*50)
    print(f"Label mapping: {', '.join([f'{k}={v}' for k, v in LABEL_MAPPING.items()])}")
    print("="*50)

    try:
        # 1. åŠ è½½è®­ç»ƒå¥½çš„ç³»ç»Ÿ
        system = load_trained_system()

        # 2. èŽ·å–éšæœºæµ‹è¯•æ ·æœ¬
        test_samples = get_test_data(sample_size=5)

        # 3. è¿›è¡Œé¢„æµ‹
        predictions = predict_samples(system, test_samples)

        # 4. æ˜¾ç¤ºç»“æžœ
        display_results(test_samples, predictions)

        print("\n" + "="*50)
        print("Testing completed!")

    except Exception as e:
        print(f"Error during testing: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()